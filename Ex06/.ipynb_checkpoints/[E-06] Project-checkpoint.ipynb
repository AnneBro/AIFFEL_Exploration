{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6ccca60",
   "metadata": {},
   "source": [
    "# [E-06] 프로젝트 : 멋진 작사가 만들기\n",
    "\n",
    "<br>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "273cfb6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import tensorflow\n",
    "\n",
    "print(tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb17a43",
   "metadata": {},
   "source": [
    "### ✔️ 필요한 라이브러리 import하기\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "f2f90a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import glob\n",
    "\n",
    "import os\n",
    "import re \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import missingno as msno\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61faa54",
   "metadata": {},
   "source": [
    "---\n",
    "### ✔️ 데이터 읽어오기\n",
    "\n",
    "---\n",
    "\n",
    "- `glob` 모듈을 사용하면 파일을 읽어오는 작업을 하기가 유용하다.<br>\n",
    "- `glob`를 활용하여 모든 `txt` 파일을 읽어온 후, `raw_corpus` 리스트에 문장 단위로 저장한다.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "f6e7bd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_file_path = os.getenv('HOME')+'/aiffel/lyricist/data/lyrics/*'\n",
    "\n",
    "txt_list = glob.glob(txt_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "c9df1194",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(txt_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "ac246f79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/aiffel/aiffel/lyricist/data/lyrics/janisjoplin.txt',\n",
       " '/aiffel/aiffel/lyricist/data/lyrics/nursery_rhymes.txt',\n",
       " '/aiffel/aiffel/lyricist/data/lyrics/dickinson.txt',\n",
       " '/aiffel/aiffel/lyricist/data/lyrics/nicki-minaj.txt',\n",
       " '/aiffel/aiffel/lyricist/data/lyrics/disney.txt',\n",
       " '/aiffel/aiffel/lyricist/data/lyrics/bob-marley.txt',\n",
       " '/aiffel/aiffel/lyricist/data/lyrics/beatles.txt',\n",
       " '/aiffel/aiffel/lyricist/data/lyrics/dj-khaled.txt',\n",
       " '/aiffel/aiffel/lyricist/data/lyrics/kanye.txt',\n",
       " '/aiffel/aiffel/lyricist/data/lyrics/patti-smith.txt',\n",
       " '/aiffel/aiffel/lyricist/data/lyrics/drake.txt',\n",
       " '/aiffel/aiffel/lyricist/data/lyrics/r-kelly.txt',\n",
       " '/aiffel/aiffel/lyricist/data/lyrics/rihanna.txt',\n",
       " '/aiffel/aiffel/lyricist/data/lyrics/cake.txt',\n",
       " '/aiffel/aiffel/lyricist/data/lyrics/bruno-mars.txt',\n",
       " '/aiffel/aiffel/lyricist/data/lyrics/leonard-cohen.txt',\n",
       " '/aiffel/aiffel/lyricist/data/lyrics/ludacris.txt',\n",
       " '/aiffel/aiffel/lyricist/data/lyrics/kanye-west.txt',\n",
       " '/aiffel/aiffel/lyricist/data/lyrics/eminem.txt',\n",
       " '/aiffel/aiffel/lyricist/data/lyrics/radiohead.txt',\n",
       " '/aiffel/aiffel/lyricist/data/lyrics/lorde.txt',\n",
       " '/aiffel/aiffel/lyricist/data/lyrics/notorious-big.txt',\n",
       " '/aiffel/aiffel/lyricist/data/lyrics/prince.txt',\n",
       " '/aiffel/aiffel/lyricist/data/lyrics/paul-simon.txt',\n",
       " '/aiffel/aiffel/lyricist/data/lyrics/bieber.txt',\n",
       " '/aiffel/aiffel/lyricist/data/lyrics/lin-manuel-miranda.txt',\n",
       " '/aiffel/aiffel/lyricist/data/lyrics/Kanye_West.txt',\n",
       " '/aiffel/aiffel/lyricist/data/lyrics/joni-mitchell.txt',\n",
       " '/aiffel/aiffel/lyricist/data/lyrics/alicia-keys.txt',\n",
       " '/aiffel/aiffel/lyricist/data/lyrics/nirvana.txt',\n",
       " '/aiffel/aiffel/lyricist/data/lyrics/johnny-cash.txt',\n",
       " '/aiffel/aiffel/lyricist/data/lyrics/missy-elliott.txt',\n",
       " '/aiffel/aiffel/lyricist/data/lyrics/bruce-springsteen.txt',\n",
       " '/aiffel/aiffel/lyricist/data/lyrics/jimi-hendrix.txt',\n",
       " '/aiffel/aiffel/lyricist/data/lyrics/bob-dylan.txt',\n",
       " '/aiffel/aiffel/lyricist/data/lyrics/bjork.txt',\n",
       " '/aiffel/aiffel/lyricist/data/lyrics/dolly-parton.txt',\n",
       " '/aiffel/aiffel/lyricist/data/lyrics/blink-182.txt',\n",
       " '/aiffel/aiffel/lyricist/data/lyrics/michael-jackson.txt',\n",
       " '/aiffel/aiffel/lyricist/data/lyrics/britney-spears.txt',\n",
       " '/aiffel/aiffel/lyricist/data/lyrics/al-green.txt',\n",
       " '/aiffel/aiffel/lyricist/data/lyrics/Lil_Wayne.txt',\n",
       " '/aiffel/aiffel/lyricist/data/lyrics/lil-wayne.txt',\n",
       " '/aiffel/aiffel/lyricist/data/lyrics/dr-seuss.txt',\n",
       " '/aiffel/aiffel/lyricist/data/lyrics/notorious_big.txt',\n",
       " '/aiffel/aiffel/lyricist/data/lyrics/lady-gaga.txt',\n",
       " '/aiffel/aiffel/lyricist/data/lyrics/nickelback.txt',\n",
       " '/aiffel/aiffel/lyricist/data/lyrics/amy-winehouse.txt',\n",
       " '/aiffel/aiffel/lyricist/data/lyrics/adele.txt']"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4581c95b",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- `txt_file_path`에 있는 모든 `txt` 파일을 읽어서 raw_corpus에 담아보자!<br><br>\n",
    "- 우선, `txt`파일 목록을 한번 살펴보고 몇개의 파일이 있는지 확인해보자!<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "09a541b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_list[0].find('lyrics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "2ad01271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "txt파일의 갯수 : 49\n",
      "\n",
      "====================\n",
      "\n",
      "0 : janisjoplin.txt\n",
      "1 : nursery_rhymes.txt\n",
      "2 : dickinson.txt\n",
      "3 : nicki-minaj.txt\n",
      "4 : disney.txt\n",
      "5 : bob-marley.txt\n",
      "6 : beatles.txt\n",
      "7 : dj-khaled.txt\n",
      "8 : kanye.txt\n",
      "9 : patti-smith.txt\n",
      "10 : drake.txt\n",
      "11 : r-kelly.txt\n",
      "12 : rihanna.txt\n",
      "13 : cake.txt\n",
      "14 : bruno-mars.txt\n",
      "15 : leonard-cohen.txt\n",
      "16 : ludacris.txt\n",
      "17 : kanye-west.txt\n",
      "18 : eminem.txt\n",
      "19 : radiohead.txt\n",
      "20 : lorde.txt\n",
      "21 : notorious-big.txt\n",
      "22 : prince.txt\n",
      "23 : paul-simon.txt\n",
      "24 : bieber.txt\n",
      "25 : lin-manuel-miranda.txt\n",
      "26 : Kanye_West.txt\n",
      "27 : joni-mitchell.txt\n",
      "28 : alicia-keys.txt\n",
      "29 : nirvana.txt\n",
      "30 : johnny-cash.txt\n",
      "31 : missy-elliott.txt\n",
      "32 : bruce-springsteen.txt\n",
      "33 : jimi-hendrix.txt\n",
      "34 : bob-dylan.txt\n",
      "35 : bjork.txt\n",
      "36 : dolly-parton.txt\n",
      "37 : blink-182.txt\n",
      "38 : michael-jackson.txt\n",
      "39 : britney-spears.txt\n",
      "40 : al-green.txt\n",
      "41 : Lil_Wayne.txt\n",
      "42 : lil-wayne.txt\n",
      "43 : dr-seuss.txt\n",
      "44 : notorious_big.txt\n",
      "45 : lady-gaga.txt\n",
      "46 : nickelback.txt\n",
      "47 : amy-winehouse.txt\n",
      "48 : adele.txt\n"
     ]
    }
   ],
   "source": [
    "# txt_list = !ls /aiffel/aiffel/lyricist/data/lyrics/*\n",
    "print(f'txt파일의 갯수 : {len(txt_list)}')\n",
    "print('\\n====================\\n'); \n",
    "for idx, txt_name in enumerate(txt_list):\n",
    "    print(idx, ':', txt_name[36:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1b3808",
   "metadata": {},
   "source": [
    "△ 유명한 가수들은 유명곡들을 담은 텍스트 파일들이 나열된 것을 확인할 수 있다.<br>자, 그럼 이제 모든 `txt` 파일을 읽어서 raw_corpus에 모든 가사를 담아보자<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "cb5ba37c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터의 크기: 187088\n",
      "Examples:\n",
      " [\"Busted flat in Baton Rouge, waitin' for a train\", \"And I's feelin' near as faded as my jeans\", 'Bobby thumbed a diesel down, just before it rained']\n"
     ]
    }
   ],
   "source": [
    "# 여러개의 txt 파일을 모두 읽어서 raw_corpus에 담는다.\n",
    "\n",
    "raw_corpus = []\n",
    "\n",
    "for txt_file in txt_list:\n",
    "    with open(txt_file, 'r') as f:\n",
    "        raw = f.read().splitlines()\n",
    "        raw_corpus.extend(raw)\n",
    "\n",
    "print('데이터의 크기:', len(raw_corpus))\n",
    "print('Examples:\\n', raw_corpus[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db86a9a",
   "metadata": {},
   "source": [
    "---\n",
    "### ✔️ 데이터 정제\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2b2d4f",
   "metadata": {},
   "source": [
    "- `raw_corpus` 변수에 187088개의 문장이 담겨있는데, 각 문장들을 살펴보자.<br><br>\n",
    "- 모든 문장을 살펴볼 수는 없으니까 10개의 문장을 보고 필터링을 해야할 단어들이 있는지 파악해본다.<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "e349473e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Busted flat in Baton Rouge, waitin' for a train\",\n",
       " \"And I's feelin' near as faded as my jeans\",\n",
       " 'Bobby thumbed a diesel down, just before it rained',\n",
       " 'It rode us all the way to New Orleans I pulled my harpoon out of my dirty red bandanna',\n",
       " \"I was playin' soft while Bobby sang the blues, yeah\",\n",
       " \"Windshield wipers slappin' time, I was holdin' Bobby's hand in mine\",\n",
       " \"We sang every song that driver knew Freedom's just another word for nothin' left to lose\",\n",
       " \"Nothin', don't mean nothin' hon' if it ain't free, no no\",\n",
       " \"And, feelin' good was easy, Lord, when he sang the blues\",\n",
       " \"You know, feelin' good was good enough for me\"]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_corpus[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed0e4c6",
   "metadata": {},
   "source": [
    "<br>△ 위 문장들을 확인해보니, 필터링이 필요한 단어들은 없는 것 같지만 공백문장이 있을 수 있으니 한번 확인해보기로 한다.<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "3292d6a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "공백문장이 11102개 있습니다.\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "\n",
    "for idx, sentence in enumerate(raw_corpus):\n",
    "    if len(sentence) == 0: \n",
    "        cnt += 1\n",
    "\n",
    "if cnt != 0:\n",
    "    print('공백문장이 {}개 있습니다.'.format(cnt))\n",
    "else:\n",
    "    print('공백문장 없음.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3aa14c",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- 공백을 가지는 문장이 11102개 있으므로 해당 데이터들의 필터링이 필요하다.<br><br>\n",
    "\n",
    "#### 앞선 노드에서 `preprocess_sentence()`라는 정제함수를 만들었다.<br><br>이 함수는 입력된 문장을 아래와 같은 방법으로 filtering 한다.<br>\n",
    "\n",
    "- 1) 소문자로 바꾸고, 양쪽 공백을 지운다.\n",
    "- 2) 특수문자 양쪽에 공백을 넣고\n",
    "- 3) 여러개의 공백은 하나의 공백으로 바꾼다\n",
    "- 4) a-zA-Z?.!,¿가 아닌 모든 문자를 하나의 공백으로 바꾼다.\n",
    "- 5) 다시 양쪽 공백을 지운다.\n",
    "- 6) 문장 시작에는 <strart>, 끝에는 <end>를 추가한다.<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "ff7dcba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower().strip() # 1\n",
    "    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence) # 2\n",
    "    sentence = re.sub(r'[\" \"]+', ' ', sentence)  #3\n",
    "    sentence = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", sentence) # 4\n",
    "    sentence = sentence.strip() # 5\n",
    "    sentence = '<start> ' + sentence + ' <end>'  #6\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e86432",
   "metadata": {},
   "source": [
    "<br>자연어처리 분야에서 모델의 입력이 되는 문장을 *`소스문장(Source Sentence)`*, <br>정답 역할을 하게 될 모델의 출력 문장을 *`타겟문장(Target Sentence)`*라고 관례적으로 부른다.<br> 각각 X_train, y_train에 해당한다고 볼 수 있다.<br><br>\n",
    "위에서 만든 정제 함수를 통해 만든 데이터셋에서 토큰화를 진행한 후 <U>끝 단어 `<end>`를 없애면 `소스문장`</U>, <U>첫 단어 `<start>`를 없애면 `타겟 문장`</U>이 된다.<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "dc931ee1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정제된 후 문장의 갯수는 175749개이다.\n",
      "\n",
      "['<start> busted flat in baton rouge , waitin for a train <end>', '<start> and i s feelin near as faded as my jeans <end>', '<start> bobby thumbed a diesel down , just before it rained <end>', '<start> it rode us all the way to new orleans i pulled my harpoon out of my dirty red bandanna <end>', '<start> i was playin soft while bobby sang the blues , yeah <end>', '<start> windshield wipers slappin time , i was holdin bobby s hand in mine <end>', '<start> we sang every song that driver knew freedom s just another word for nothin left to lose <end>', '<start> nothin , don t mean nothin hon if it ain t free , no no <end>', '<start> and , feelin good was easy , lord , when he sang the blues <end>', '<start> you know , feelin good was good enough for me <end>']\n"
     ]
    }
   ],
   "source": [
    "# 여기에 정제된 문장을 모아보자.\n",
    "corpus = []\n",
    "\n",
    "for sentence in raw_corpus:\n",
    "    # 우리가 원하지 않는 문장은 건너뛴다.\n",
    "    if (len(sentence) == 0): continue\n",
    "    if sentence[-1] == \":\": continue\n",
    "    \n",
    "    # 정제를 하고 담아보자\n",
    "    preprocessed_sentence = preprocess_sentence(sentence)\n",
    "    corpus.append(preprocessed_sentence)\n",
    "        \n",
    "# 정제된 결과를 10개만 확인해보자.\n",
    "\n",
    "print('정제된 후 문장의 갯수는 {}개이다.'.format(len(corpus)))\n",
    "print()\n",
    "print(corpus[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e87dee6",
   "metadata": {},
   "source": [
    "데이터는 이제 완전하게 준비가 되었다.<br>우리가 가르칠 언어(data)를 인공지능의 모국어인 숫자로 변환해보자<br><br>텐서플로우는 자연어 처리를 위한 여러가지 모듈을 제공하는데 `tf.keras.preprocessing.text.Tokenizer` 패키지는 <U>1) 정제된 데이터를 토큰화</U>하고,<br><U>2) 단어사전(vocabulary 또는 dictionary라고 칭함)을 만들</U>어주며, <U>3) 데이터를 숫자로 변환</U>까지 한방에 해준다.<br><br>이 과정을 **벡터화(vectorize)**라고 하며, 숫자로 변환된 데이터를 **텐서(tensor)**라고 칭한다.<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd77e4bb",
   "metadata": {},
   "source": [
    "또한, 이번 프로젝트에서 처리해야할 중요한 부분이 있다.<br><br>작사 중 지나치게 긴 문장들이 존재하는데, 이러한 문장들은 다른 데이터들이 과도한 padding을 갖게하므로 제거한다.<br>왜냐하면 너무 긴 문장은 노래 가사를 작사하기에 어울리지 않기 때문이다.<br><br>따라서 **토큰화 했을 때 토큰의 갯수가 15개를 넘어가는 문장은 학습데이터에서 제외**하기로 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "a1bb444e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   2 3604 1691 ...    0    0    0]\n",
      " [   2    8    5 ...    0    0    0]\n",
      " [   2  804 7655 ...    0    0    0]\n",
      " ...\n",
      " [   2   20   20 ...    3    0    0]\n",
      " [   2   20 4178 ...    0    0    0]\n",
      " [   2    3    0 ...    0    0    0]] <keras_preprocessing.text.Tokenizer object at 0x7f50113956d0>\n"
     ]
    }
   ],
   "source": [
    "# 토큰화 할 때 텐서플로우의 Tokenizer와 pad_sequences를 사용합니다\n",
    "# 더 잘 알기 위해 아래 문서들을 참고하면 좋습니다\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/sequence/pad_sequences\n",
    "def tokenize(corpus):\n",
    "    # 7000단어를 기억할 수 있는 tokenizer를 만들겁니다\n",
    "    # 우리는 이미 문장을 정제했으니 filters가 필요없어요\n",
    "    # 7000단어에 포함되지 못한 단어는 '<unk>'로 바꿀거에요\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "        num_words=12000, \n",
    "        filters=' ',\n",
    "        oov_token=\"<unk>\"\n",
    "    )\n",
    "    # corpus를 이용해 tokenizer 내부의 단어장을 완성합니다\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "    # 준비한 tokenizer를 이용해 corpus를 Tensor로 변환합니다\n",
    "    tensor = tokenizer.texts_to_sequences(corpus)   \n",
    "    tensor_filt = [] # 토큰의 갯수가 14개 이하인 문장만 담기위해\n",
    "    \n",
    "    for i in range(len(tensor)):\n",
    "        if len(tensor[i]) <= 15:\n",
    "            tensor_filt.append(tensor[i])\n",
    "        \n",
    "    # 입력 데이터의 시퀀스 길이를 일정하게 맞춰줍니다\n",
    "    # 만약 시퀀스가 짧다면 문장 뒤에 패딩을 붙여 길이를 맞춰줍니다.\n",
    "    # 문장 앞에 패딩을 붙여 길이를 맞추고 싶다면 padding='pre'를 사용합니다\n",
    "    tensor_filt = tf.keras.preprocessing.sequence.pad_sequences(tensor_filt, padding='post')  \n",
    "    \n",
    "    print(tensor_filt,tokenizer)\n",
    "    return tensor_filt, tokenizer\n",
    "\n",
    "tensor_filt, tokenizer = tokenize(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2248f661",
   "metadata": {},
   "source": [
    "#### 새롭게 정제된 문장을 보게되면 (156013, 15)개의 크기를 갖는것을 확인한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "9c225a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156013, 15)\n"
     ]
    }
   ],
   "source": [
    "print(tensor_filt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "2a6a9c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   2 3604 1691   14 7050 3995    4 1100   28    9]\n",
      " [   2    8    5   16  512  848   81 2584   81   13]\n",
      " [   2  804 7655    9 6042   60    4   35  185   11]\n",
      " [   2    5   57  873  962  234  804 1731    6  927]\n",
      " [   2 5629 7656 4179   73    4    5   57 1162  804]\n",
      " [   2    7   34    4  512  108   57  108  264   28]\n",
      " [   2   65  804 3390    6 1898   19   13  325    3]\n",
      " [   2  132   24 2963   19 1676    4  132  183   23]\n",
      " [   2   55   16  469   28   17  159    4    8    5]\n",
      " [   2  484    4   17   16   24   17  804  244   12]]\n"
     ]
    }
   ],
   "source": [
    "# 생성된 텐서 데이터를 3번째 행, 10번째 열까지만 출력해 보자\n",
    "\n",
    "print(tensor_filt[:10, :10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f779b7a",
   "metadata": {},
   "source": [
    "<br>텐서 데이터는 모두 정수로 이루어져 있으며 이 숫자는 tokenizer에 구축된 단어사전의 인덱스이다.<br><br>\n",
    "\n",
    "- `tokenizer.index_word` : 말뭉치(corpus)를 토큰화 시킨 후 단어사전(dictionary 객체)\n",
    "- `tokenizer.num_words` :  토큰화된 단어의 갯수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "c9e19b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : <unk>\n",
      "2 : <start>\n",
      "3 : <end>\n",
      "4 : ,\n",
      "5 : i\n",
      "6 : the\n",
      "7 : you\n",
      "8 : and\n",
      "9 : a\n",
      "10 : to\n"
     ]
    }
   ],
   "source": [
    "# 단어사전이 어떻게 구축되어 있는지 살펴보면...\n",
    "\n",
    "for idx in tokenizer.index_word:\n",
    "    print(idx, ':', tokenizer.index_word[idx])\n",
    "    \n",
    "    if idx >= 10: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "5ea06a59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12000"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 토큰화된 단어의 갯수\n",
    "\n",
    "tokenizer.num_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223da09c",
   "metadata": {},
   "source": [
    "<br>이제 생성된 텐서를 소스와 타겟으로 분리하여 모델이 학습할 수 있도록 한다.<br><br>텐서 출력부에서 행 뒤쪽에 0이 많이 나온 부분은 정해진 입력 시쿼스 길이보다 문장이 짧을 경우 0으로 패딩(padding)을 채워 넣은 것이다.<br><br>사전에는 없지만 0은 바로 패딩 문자 `<pad>`가 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "22f8a0f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156013, 14)\n",
      "(156013, 14)\n",
      "[   2 3604 1691   14 7050 3995    4 1100   28    9  681    3    0    0]\n",
      "[3604 1691   14 7050 3995    4 1100   28    9  681    3    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "# tensor에서 마지막 토큰을 잘라내서 소스 문장을 생성합니다\n",
    "# 마지막 토큰은 <end>가 아니라 <pad>일 가능성이 높습니다.\n",
    "src_input = tensor_filt[:, :-1]  \n",
    "# tensor에서 <start>를 잘라내서 타겟 문장을 생성합니다.\n",
    "tgt_input = tensor_filt[:, 1:]    \n",
    "\n",
    "print(src_input.shape)\n",
    "print(tgt_input.shape)\n",
    "\n",
    "print(src_input[0])\n",
    "print(tgt_input[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e51580a",
   "metadata": {},
   "source": [
    "---\n",
    "### ✔️ 평가 데이터셋 분리\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "408170f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "419bdd74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Train : (124810, 14)\n",
      "Target Train : (124810, 14)\n",
      "Source Val : (31203, 14)\n",
      "Target Val : (31203, 14)\n"
     ]
    }
   ],
   "source": [
    "enc_train, enc_val, dec_train, dec_val = train_test_split(src_input, tgt_input, test_size=0.2, random_state=2022)\n",
    "\n",
    "print('Source Train :', enc_train.shape)\n",
    "print('Target Train :', dec_train.shape)\n",
    "print('Source Val :', enc_val.shape)\n",
    "print('Target Val :', dec_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "820d924e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((256, 14), (256, 14)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BUFFER_SIZE = len(enc_train)\n",
    "BATCH_SIZE = 256\n",
    "# steps_per_epoch = len(src_input) // BATCH_SIZE\n",
    "\n",
    " # tokenizer가 구축한 단어사전 내 12000개와, 여기 포함되지 않은 0:<pad>를 포함하여 12001개\n",
    "VOCAB_SIZE = tokenizer.num_words + 1   \n",
    "\n",
    "# 준비한 데이터 소스로부터 데이터셋을 만듭니다\n",
    "# 데이터셋에 대해서는 아래 문서를 참고하세요\n",
    "# 자세히 알아둘수록 도움이 많이 되는 중요한 문서입니다\n",
    "# https://www.tensorflow.org/api_docs/python/tf/data/Dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices((enc_train, dec_train))\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "8b5b24a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((256, 14), (256, 14)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BUFFER_SIZE = len(enc_val)\n",
    "BATCH_SIZE = 256\n",
    "# steps_per_epoch = len(src_input) // BATCH_SIZE\n",
    "\n",
    " # tokenizer가 구축한 단어사전 내 12000개와, 여기 포함되지 않은 0:<pad>를 포함하여 12001개\n",
    "VOCAB_SIZE = tokenizer.num_words + 1   \n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((enc_train, dec_train))\n",
    "val_dataset = val_dataset.shuffle(BUFFER_SIZE)\n",
    "val_dataset = val_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "val_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e7275b",
   "metadata": {},
   "source": [
    "#### 이번 스텝에서 데이터셋을 생성하기 위해 거쳐 온 과정을 기억해두자. == `데이터 전처리`\n",
    "\n",
    "- 정규 표현식을 사용해서 corpus 생성\n",
    "- `tf.keras.preprocessing.text.Tokenizer`를 이용해 corpus를 텐서로 변환\n",
    "- `tf.data.Dataset.from_tensor_slices()`를 이용해 corpus 텐서를 `tf.data.Dataset` 객체로 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2c1209",
   "metadata": {},
   "source": [
    "---\n",
    "### ✔️ 인공지능 학습시키기\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b216138",
   "metadata": {},
   "source": [
    "<img src = 'https://user-images.githubusercontent.com/103712369/168005994-ca087f67-4703-4b3e-b9b0-efc083c326da.png' width ='500' height='50'/><br>\n",
    "\n",
    "<br>우리가 만들 모델은 tf.keras.Model을 Subclassing 하는 방식으로 만든다.<br>우리 모델에는 1개의 Embedding 레이어, 2개의 LSTM 레이어, 1개의 Dense 레이어로 구성됨.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "121475ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextGenerator(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
    "        self.rnn_1 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.rnn_2 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.linear = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "    def call(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = self.rnn_1(out)\n",
    "        out = self.rnn_2(out)\n",
    "        out = self.linear(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "embedding_size = 256\n",
    "hidden_size = 1024\n",
    "model = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "b887b77b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(256, 14, 12001), dtype=float32, numpy=\n",
       "array([[[ 2.13503354e-05, -2.90875760e-05, -8.46181138e-05, ...,\n",
       "         -1.06970023e-04,  3.14476260e-04, -1.20200355e-04],\n",
       "        [ 9.91899506e-05, -5.09362617e-05, -5.43419537e-06, ...,\n",
       "         -4.57951770e-04,  4.26878454e-04, -2.23781506e-04],\n",
       "        [ 2.73446843e-04,  2.44476425e-04,  1.20835204e-04, ...,\n",
       "         -3.80774873e-04,  6.46780769e-04, -1.19340577e-04],\n",
       "        ...,\n",
       "        [-9.48117289e-04, -7.44814111e-04,  4.66682512e-04, ...,\n",
       "         -1.29898428e-03,  9.94084985e-04,  1.18531566e-03],\n",
       "        [-1.12291728e-03, -6.52765681e-04,  8.58927146e-04, ...,\n",
       "         -1.49747427e-03,  9.06364701e-04,  1.43014232e-03],\n",
       "        [-1.22591155e-03, -5.58944710e-04,  1.21500809e-03, ...,\n",
       "         -1.71311561e-03,  7.89864978e-04,  1.63720280e-03]],\n",
       "\n",
       "       [[ 2.13503354e-05, -2.90875760e-05, -8.46181138e-05, ...,\n",
       "         -1.06970023e-04,  3.14476260e-04, -1.20200355e-04],\n",
       "        [-2.74841237e-04,  2.85097985e-06, -1.12766116e-04, ...,\n",
       "          2.27404889e-05,  5.55733801e-04, -7.52577489e-06],\n",
       "        [-4.79546783e-04, -8.82003806e-05, -3.64293192e-05, ...,\n",
       "         -6.61876547e-05,  7.63299118e-04,  8.44761089e-05],\n",
       "        ...,\n",
       "        [-1.17947138e-03,  3.44927539e-04,  2.21824553e-03, ...,\n",
       "         -1.18353742e-03,  3.67401604e-04,  1.54756091e-03],\n",
       "        [-1.11073314e-03,  3.43430496e-04,  2.44836113e-03, ...,\n",
       "         -1.44704652e-03,  2.54900166e-04,  1.70889520e-03],\n",
       "        [-1.02539931e-03,  3.33237695e-04,  2.61868513e-03, ...,\n",
       "         -1.68889365e-03,  1.44953985e-04,  1.84530881e-03]],\n",
       "\n",
       "       [[ 2.13503354e-05, -2.90875760e-05, -8.46181138e-05, ...,\n",
       "         -1.06970023e-04,  3.14476260e-04, -1.20200355e-04],\n",
       "        [-2.92414879e-05, -4.51002998e-04,  1.11055579e-05, ...,\n",
       "          6.33540403e-05,  3.09605326e-04, -4.07277548e-04],\n",
       "        [-1.89175713e-04, -8.79371597e-04, -1.63730409e-04, ...,\n",
       "          4.17976589e-05,  2.92085431e-04, -3.59048514e-04],\n",
       "        ...,\n",
       "        [ 4.47990664e-04, -4.14178474e-04, -4.64522600e-04, ...,\n",
       "          3.48640169e-04,  8.86514026e-05,  8.85715883e-04],\n",
       "        [ 7.22752127e-04, -1.19913857e-04, -2.26331656e-04, ...,\n",
       "          3.66017921e-04,  9.61760816e-06,  7.47019309e-04],\n",
       "        [ 8.77144921e-04,  5.82188222e-05,  2.08195022e-04, ...,\n",
       "          2.72889010e-04,  7.53979912e-05,  7.79483642e-04]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 2.13503354e-05, -2.90875760e-05, -8.46181138e-05, ...,\n",
       "         -1.06970023e-04,  3.14476260e-04, -1.20200355e-04],\n",
       "        [-2.92414879e-05, -4.51002998e-04,  1.11055579e-05, ...,\n",
       "          6.33540403e-05,  3.09605326e-04, -4.07277548e-04],\n",
       "        [-1.71834195e-04, -7.51653221e-04,  2.06471988e-04, ...,\n",
       "          1.80221861e-04,  3.52941744e-04, -3.77762568e-04],\n",
       "        ...,\n",
       "        [-1.34170987e-04,  7.96874461e-04,  9.33554838e-04, ...,\n",
       "          6.56508550e-04,  3.21736356e-04,  5.15116844e-04],\n",
       "        [-3.24836874e-04,  7.50679581e-04,  1.35723373e-03, ...,\n",
       "          3.16561200e-04,  3.59061523e-04,  6.88774453e-04],\n",
       "        [-4.71081090e-04,  6.83288439e-04,  1.73784408e-03, ...,\n",
       "         -7.09064043e-05,  3.74404655e-04,  8.66099843e-04]],\n",
       "\n",
       "       [[ 2.13503354e-05, -2.90875760e-05, -8.46181138e-05, ...,\n",
       "         -1.06970023e-04,  3.14476260e-04, -1.20200355e-04],\n",
       "        [ 1.94829845e-05, -3.42333187e-05, -2.41585920e-04, ...,\n",
       "         -3.31034360e-04,  3.87435837e-04, -3.01678170e-04],\n",
       "        [ 5.12759070e-05, -3.40215251e-04, -3.05759400e-04, ...,\n",
       "         -4.14351845e-04,  6.83589780e-04, -4.47475875e-04],\n",
       "        ...,\n",
       "        [-6.94878225e-04, -6.44489308e-04,  9.35874530e-04, ...,\n",
       "         -4.78300557e-04,  5.83009794e-04,  3.09499126e-04],\n",
       "        [-8.34916602e-04, -4.65505611e-04,  1.28184119e-03, ...,\n",
       "         -7.44327088e-04,  4.87009034e-04,  5.87312970e-04],\n",
       "        [-9.13680764e-04, -3.07047478e-04,  1.58728822e-03, ...,\n",
       "         -1.02223526e-03,  3.81637714e-04,  8.52079131e-04]],\n",
       "\n",
       "       [[ 2.13503354e-05, -2.90875760e-05, -8.46181138e-05, ...,\n",
       "         -1.06970023e-04,  3.14476260e-04, -1.20200355e-04],\n",
       "        [ 2.56076280e-04, -1.72843196e-04,  8.97976133e-05, ...,\n",
       "         -1.57244140e-04,  5.03058487e-04, -1.96449138e-04],\n",
       "        [ 3.13789933e-04, -4.63686330e-04,  7.82896241e-05, ...,\n",
       "         -3.72922776e-04,  7.41645694e-04, -1.25845705e-04],\n",
       "        ...,\n",
       "        [-7.94728403e-04, -1.47149200e-04,  1.92032382e-03, ...,\n",
       "         -1.58567203e-03,  4.32867324e-04,  1.29523664e-03],\n",
       "        [-8.44905037e-04, -6.22810767e-05,  2.10701046e-03, ...,\n",
       "         -1.82648713e-03,  3.49479000e-04,  1.45043992e-03],\n",
       "        [-8.54026875e-04,  2.44993112e-06,  2.25289399e-03, ...,\n",
       "         -2.04298436e-03,  2.60516303e-04,  1.58851780e-03]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터셋에서 데이터 한 배치만 불러오는 방법입니다.\n",
    "# 지금은 동작 원리에 너무 빠져들지 마세요~\n",
    "for src_sample, tgt_sample in dataset.take(1): break  # take:: 배치를 불러오는 것.\n",
    "\n",
    "# 한 배치만 불러온 데이터를 모델에 넣어봅니다\n",
    "model(src_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c15057",
   "metadata": {},
   "source": [
    "- 모델의 최종 출력 텐서 shape를 유심히 보면 `shape=(256, 14, 12001)`임을 알 수 있다.<br>\n",
    "- 12001은 Dense 레이어의 출력 차원수.<br>\n",
    "- 12001개 단어 중 어느 단어의 확률이 가장 높을지를 모델링해야 함.<br><br>\n",
    "\n",
    "##### 256은 이전 스텝에서 지정한 배치사이즈. `dataset.take(1)`를 통해서 1개의 배치, 즉 256개의 문장 데이터를 가져온다.<br><br>\n",
    "##### 14은 `tf.keras.layers.LSTM(hidden_size, return_sequences=True)`로 호출한 LSTM 레이어에서 return~=True로 지정한 부분에 있다.<br>즉, LSTM은 자신에게 입력된 시퀀스의 길이만큼 동일한 길이의 시퀀스를 출력한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "d301e49f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"text_generator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        multiple                  3072256   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  multiple                  5246976   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                multiple                  8392704   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  12301025  \n",
      "=================================================================\n",
      "Total params: 29,012,961\n",
      "Trainable params: 29,012,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "bb3fa569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_464/337460670.py:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "185b0c01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "83a7f976",
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer\n",
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "092cde02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "dafde62f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "487/487 [==============================] - 103s 207ms/step - loss: 3.4879 - val_loss: 3.1115\n",
      "Epoch 2/10\n",
      "487/487 [==============================] - 105s 215ms/step - loss: 3.0268 - val_loss: 2.9040\n",
      "Epoch 3/10\n",
      "487/487 [==============================] - 106s 218ms/step - loss: 2.8634 - val_loss: 2.7590\n",
      "Epoch 4/10\n",
      "487/487 [==============================] - 106s 218ms/step - loss: 2.7371 - val_loss: 2.6428\n",
      "Epoch 5/10\n",
      "487/487 [==============================] - 106s 218ms/step - loss: 2.6305 - val_loss: 2.5380\n",
      "Epoch 6/10\n",
      "487/487 [==============================] - 106s 218ms/step - loss: 2.5354 - val_loss: 2.4454\n",
      "Epoch 7/10\n",
      "487/487 [==============================] - 106s 218ms/step - loss: 2.4480 - val_loss: 2.3606\n",
      "Epoch 8/10\n",
      "487/487 [==============================] - 106s 218ms/step - loss: 2.3665 - val_loss: 2.2800\n",
      "Epoch 9/10\n",
      "487/487 [==============================] - 106s 218ms/step - loss: 2.2899 - val_loss: 2.2051\n",
      "Epoch 10/10\n",
      "487/487 [==============================] - 106s 218ms/step - loss: 2.2172 - val_loss: 2.1304\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=loss, optimizer=optimizer)\n",
    "\n",
    "### validation_data 데이터셋을 넣어서 validation loss 그래프 그려보자 history 적용해보기\n",
    "hist = model.fit(dataset, epochs=10, validation_data=val_dataset)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69719aa",
   "metadata": {},
   "source": [
    "---\n",
    "### ✔️ Plot Performance\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "de63bb36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(hist.history['loss'], color='teal', label='loss')\n",
    "plt.plot(hist.history['val_loss'], color='orange', label='val_loss')\n",
    "fig.suptitle('Loss', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d12f507",
   "metadata": {},
   "source": [
    "---\n",
    "### ✔️ Evaluate\n",
    "\n",
    "---\n",
    "\n",
    "- 이번에는 작문 모델을 평가하기 위해 작문된 문장을 사람이 평가해본다.<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "60476ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, tokenizer, init_sentence=\"<start>\", max_len=14):\n",
    "    # 테스트를 위해서 입력받은 init_sentence도 텐서로 변환합니다\n",
    "    test_input = tokenizer.texts_to_sequences([init_sentence])\n",
    "    test_tensor = tf.convert_to_tensor(test_input, dtype=tf.int64)\n",
    "    end_token = tokenizer.word_index[\"<end>\"]\n",
    "\n",
    "    # 단어 하나씩 예측해 문장을 만듭니다\n",
    "    #    1. 입력받은 문장의 텐서를 입력합니다\n",
    "    #    2. 예측된 값 중 가장 높은 확률인 word index를 뽑아냅니다\n",
    "    #    3. 2에서 예측된 word index를 문장 뒤에 붙입니다\n",
    "    #    4. 모델이 <end>를 예측했거나, max_len에 도달했다면 문장 생성을 마칩니다\n",
    "    while True:\n",
    "        # 1\n",
    "        predict = model(test_tensor) \n",
    "        # 2\n",
    "        predict_word = tf.argmax(tf.nn.softmax(predict, axis=-1), axis=-1)[:, -1] \n",
    "        # 3 \n",
    "        test_tensor = tf.concat([test_tensor, tf.expand_dims(predict_word, axis=0)], axis=-1)\n",
    "        # 4\n",
    "        if predict_word.numpy()[0] == end_token: break\n",
    "        if test_tensor.shape[1] >= max_len: break\n",
    "\n",
    "    generated = \"\"\n",
    "    # tokenizer를 이용해 word index를 단어로 하나씩 변환합니다 \n",
    "    for word_index in test_tensor[0].numpy():\n",
    "        generated += tokenizer.index_word[word_index] + \" \"\n",
    "\n",
    "    return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "c907660d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> i love you , liberian girl <end> '"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> i love\", max_len=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4863e8cc",
   "metadata": {},
   "source": [
    "---\n",
    "### ✔️ 결론\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48d51c1",
   "metadata": {},
   "source": [
    "- 이번 Exploration Node는 `텍스트 생성모델`을 만들어보는 과정이다.<br><br> \n",
    "- 1) 맨 처음 진행한 작업은 데이터 전처리를 해주었다. `텍스트 생성모델`에서도 텍스트 분류 모델처럼 단어사전을 만들어야 하기 때문에 공백을 기준으로 토큰화를 진행하였다. 토큰화 과정 중 발생할 수 있는 문제를 해결하기 위해 정규표현식(Regex)를 사용하여 필터링하였다. `tf.keras.preprocessing.text.Tokenizer` 패키지를 사용해 정제된 데이터를 토큰화하고, 단어사전을 만들어주는 `벡터화(vectorize)`를 진행하였다. 작사 중 지나치게 긴 문장들이 존재하는데, 이러한 문장들은 다른 데이터들이 과도한 padding을 갖게하므로 제거한다.<br>왜냐하면 너무 긴 문장은 노래 가사를 작사하기에 어울리지 않기 때문이다.<br><br>따라서 **토큰화 했을 때 토큰의 갯수가 15개를 넘어가는 문장은 학습데이터에서 제외**하였다. 학습데이터와 벨리데이션 데이터 분리하였다.<br><br>\n",
    "- 2) 다음으로 모델학습에서는 1개의 Embedding 레이어, 2개의 LSTM 레이어, 1개의 Dense 레이어로 구성하여 학습을 진행하였다. `embedding_size` = 256, `hidden_size` = 1024 `model.compile` 과정에서 optimizer는 Adam을 사용하였으며, loss는  SparseCategoricalCrossentropy를 사용하여 진행하였다. 학습은 총 10 epoch로 진행하였다. \n",
    "`val_loss`는 2.1304로 루브릭 평가기준을 만족하였다.<br><br>\n",
    "![image](https://user-images.githubusercontent.com/103712369/169141711-30424fb5-c56f-4ac9-9db5-ad5255d6bc48.png)<br>![image](https://user-images.githubusercontent.com/103712369/169141812-152b9772-773a-4475-a643-1c8f24963482.png)<br><br>\n",
    "- 최종적으로 모델에 i love라는 입력이 주어졌을 때 생성한 문장은 다음과 같았다.<br>\n",
    "![image](https://user-images.githubusercontent.com/103712369/169141939-6b162d9d-3edd-4a64-a9df-aa7428a730a6.png)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
