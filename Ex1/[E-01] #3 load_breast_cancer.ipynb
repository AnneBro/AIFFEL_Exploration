{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59209145",
   "metadata": {},
   "source": [
    "# 프로젝트 (3) load_breast_cancer : 유방암 여부를 진단해 봅시다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3287f19",
   "metadata": {},
   "source": [
    "- 세번째 실습 : 제공된 데이터를 활용하여 환자의 유방암 여부를 분류해보자.\n",
    "    - 여러사람의 건강지표에 대한 데이터가 feature로 들어가있고, 유방암의 여부가 True/False로 Label이 됨\n",
    "\n",
    "\n",
    "- Scikit-Learn 라이브러리의 datasets를 모듈 안의 load_breast_cancer 매서드 사용해서 프로젝트를 진행"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea5fe03",
   "metadata": {},
   "source": [
    "---\n",
    "### (1) 필요한 모듈 import 하기\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f4e48f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer  # 실습파일 불러오기\n",
    "from sklearn.model_selection import train_test_split  # model_selection 모듈 안의 Train / Test Set을 나누기 위한 함수 불러오기\n",
    "from sklearn.metrics import classification_report  # metrics 모듈 안의 학습 모델을 평가하기 위한 함수 불러오기\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import pandas as pd  # pandas 모듈 불러오기\n",
    "import numpy as np   # numpy 모듈 불러오기\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70429cf",
   "metadata": {},
   "source": [
    "---\n",
    "### (2) 데이터 준비\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d22b7b37",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils.Bunch"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breast_cancer = load_breast_cancer()  # load_breast_cancer 매서드를 사용해서 breast_cancer 데이터 불러옴\n",
    "type(breast_cancer)  # breast_cancer의 타입을 구하면 파이썬 딕셔너리, 번치(bunch) 객체로 표현됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067f17fc",
   "metadata": {},
   "source": [
    "- `breast_cancer.keys()` 매서드를 사용해서 `breast_cancer` 객체 안의 정보 확인해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05819702",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breast_cancer.keys()  # digits의 속성 확인하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c70bdc1",
   "metadata": {},
   "source": [
    "* `breast_cancer`의 데이터 정보를 파악하기 위해 pandas 모듈의 DataFrame을 활용해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8230ad3f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                   0.07871  ...          17.33           184.60      2019.0   \n",
       "1                   0.05667  ...          23.41           158.80      1956.0   \n",
       "2                   0.05999  ...          25.53           152.50      1709.0   \n",
       "3                   0.09744  ...          26.50            98.87       567.7   \n",
       "4                   0.05883  ...          16.67           152.20      1575.0   \n",
       "..                      ...  ...            ...              ...         ...   \n",
       "564                 0.05623  ...          26.40           166.10      2027.0   \n",
       "565                 0.05533  ...          38.25           155.00      1731.0   \n",
       "566                 0.05648  ...          34.12           126.70      1124.0   \n",
       "567                 0.07016  ...          39.42           184.60      1821.0   \n",
       "568                 0.05884  ...          30.37            59.16       268.6   \n",
       "\n",
       "     worst smoothness  worst compactness  worst concavity  \\\n",
       "0             0.16220            0.66560           0.7119   \n",
       "1             0.12380            0.18660           0.2416   \n",
       "2             0.14440            0.42450           0.4504   \n",
       "3             0.20980            0.86630           0.6869   \n",
       "4             0.13740            0.20500           0.4000   \n",
       "..                ...                ...              ...   \n",
       "564           0.14100            0.21130           0.4107   \n",
       "565           0.11660            0.19220           0.3215   \n",
       "566           0.11390            0.30940           0.3403   \n",
       "567           0.16500            0.86810           0.9387   \n",
       "568           0.08996            0.06444           0.0000   \n",
       "\n",
       "     worst concave points  worst symmetry  worst fractal dimension  label  \n",
       "0                  0.2654          0.4601                  0.11890      0  \n",
       "1                  0.1860          0.2750                  0.08902      0  \n",
       "2                  0.2430          0.3613                  0.08758      0  \n",
       "3                  0.2575          0.6638                  0.17300      0  \n",
       "4                  0.1625          0.2364                  0.07678      0  \n",
       "..                    ...             ...                      ...    ...  \n",
       "564                0.2216          0.2060                  0.07115      0  \n",
       "565                0.1628          0.2572                  0.06637      0  \n",
       "566                0.1418          0.2218                  0.07820      0  \n",
       "567                0.2650          0.4087                  0.12400      0  \n",
       "568                0.0000          0.2871                  0.07039      1  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breast_cancer_df = pd.DataFrame(data=breast_cancer.data, columns=breast_cancer.feature_names)\n",
    "breast_cancer_df['label'] = breast_cancer.target\n",
    "breast_cancer_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "728ce800",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    357\n",
       "0    212\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breast_cancer_df['label'].value_counts()  # breast_cancer의 target 값 중 unique한 값들의 중복되는 갯수는 다음과 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38d5f32",
   "metadata": {},
   "source": [
    "* `breast_cancer`의 feature data의 크기는 569x30 이며 총 569개의 샘플 데이터가 있으며 30개의 특성을 갖는다.\n",
    "\n",
    "\n",
    "* label은 [1|0]인 True or False 로 나누어진다.\n",
    "\n",
    "\n",
    "* feature는 <br>['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
    " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
    " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
    " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
    " 'smoothness error' 'compactness error' 'concavity error'\n",
    " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
    " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
    " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
    " 'worst concave points' 'worst symmetry' 'worst fractal dimension']<br>로 나누어진다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5315ab7",
   "metadata": {},
   "source": [
    "---\n",
    "### (3) 데이터 이해하기\n",
    "---\n",
    "\n",
    "**1) Feature Data 지정하기**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b87110a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 30)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "breast_cancer_data = breast_cancer.data  # Feature Data 지정\n",
    "print(breast_cancer_data.shape)   # Feature Data의 모양 출력\n",
    "print(type(breast_cancer_data))   # Feature Data의 객체 타입 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c967f16",
   "metadata": {},
   "source": [
    "**2) Label Data 지정하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "766cc333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569,)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "breast_cancer_label = breast_cancer.target  # Label Data 지정\n",
    "print(breast_cancer_label.shape)     # Label Data의 모양 출력\n",
    "print(type(breast_cancer_label))     # Label Data의 객체 타입 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba29416",
   "metadata": {},
   "source": [
    "**3) Target Names 출력해보기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34add8ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['malignant' 'benign']\n"
     ]
    }
   ],
   "source": [
    "breast_cancer_target_names = breast_cancer.target_names\n",
    "print(breast_cancer_target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98b4b5f",
   "metadata": {},
   "source": [
    "**4) 데이터 Describe 해보기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a69bb92",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _breast_cancer_dataset:\n",
      "\n",
      "Breast cancer wisconsin (diagnostic) dataset\n",
      "--------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 569\n",
      "\n",
      "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
      "\n",
      "    :Attribute Information:\n",
      "        - radius (mean of distances from center to points on the perimeter)\n",
      "        - texture (standard deviation of gray-scale values)\n",
      "        - perimeter\n",
      "        - area\n",
      "        - smoothness (local variation in radius lengths)\n",
      "        - compactness (perimeter^2 / area - 1.0)\n",
      "        - concavity (severity of concave portions of the contour)\n",
      "        - concave points (number of concave portions of the contour)\n",
      "        - symmetry\n",
      "        - fractal dimension (\"coastline approximation\" - 1)\n",
      "\n",
      "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
      "        worst/largest values) of these features were computed for each image,\n",
      "        resulting in 30 features.  For instance, field 0 is Mean Radius, field\n",
      "        10 is Radius SE, field 20 is Worst Radius.\n",
      "\n",
      "        - class:\n",
      "                - WDBC-Malignant\n",
      "                - WDBC-Benign\n",
      "\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ===================================== ====== ======\n",
      "                                           Min    Max\n",
      "    ===================================== ====== ======\n",
      "    radius (mean):                        6.981  28.11\n",
      "    texture (mean):                       9.71   39.28\n",
      "    perimeter (mean):                     43.79  188.5\n",
      "    area (mean):                          143.5  2501.0\n",
      "    smoothness (mean):                    0.053  0.163\n",
      "    compactness (mean):                   0.019  0.345\n",
      "    concavity (mean):                     0.0    0.427\n",
      "    concave points (mean):                0.0    0.201\n",
      "    symmetry (mean):                      0.106  0.304\n",
      "    fractal dimension (mean):             0.05   0.097\n",
      "    radius (standard error):              0.112  2.873\n",
      "    texture (standard error):             0.36   4.885\n",
      "    perimeter (standard error):           0.757  21.98\n",
      "    area (standard error):                6.802  542.2\n",
      "    smoothness (standard error):          0.002  0.031\n",
      "    compactness (standard error):         0.002  0.135\n",
      "    concavity (standard error):           0.0    0.396\n",
      "    concave points (standard error):      0.0    0.053\n",
      "    symmetry (standard error):            0.008  0.079\n",
      "    fractal dimension (standard error):   0.001  0.03\n",
      "    radius (worst):                       7.93   36.04\n",
      "    texture (worst):                      12.02  49.54\n",
      "    perimeter (worst):                    50.41  251.2\n",
      "    area (worst):                         185.2  4254.0\n",
      "    smoothness (worst):                   0.071  0.223\n",
      "    compactness (worst):                  0.027  1.058\n",
      "    concavity (worst):                    0.0    1.252\n",
      "    concave points (worst):               0.0    0.291\n",
      "    symmetry (worst):                     0.156  0.664\n",
      "    fractal dimension (worst):            0.055  0.208\n",
      "    ===================================== ====== ======\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
      "\n",
      "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
      "\n",
      "    :Donor: Nick Street\n",
      "\n",
      "    :Date: November, 1995\n",
      "\n",
      "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
      "https://goo.gl/U2Uwz2\n",
      "\n",
      "Features are computed from a digitized image of a fine needle\n",
      "aspirate (FNA) of a breast mass.  They describe\n",
      "characteristics of the cell nuclei present in the image.\n",
      "\n",
      "Separating plane described above was obtained using\n",
      "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
      "Construction Via Linear Programming.\" Proceedings of the 4th\n",
      "Midwest Artificial Intelligence and Cognitive Science Society,\n",
      "pp. 97-101, 1992], a classification method which uses linear\n",
      "programming to construct a decision tree.  Relevant features\n",
      "were selected using an exhaustive search in the space of 1-4\n",
      "features and 1-3 separating planes.\n",
      "\n",
      "The actual linear program used to obtain the separating plane\n",
      "in the 3-dimensional space is that described in:\n",
      "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
      "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
      "Optimization Methods and Software 1, 1992, 23-34].\n",
      "\n",
      "This database is also available through the UW CS ftp server:\n",
      "\n",
      "ftp ftp.cs.wisc.edu\n",
      "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
      "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
      "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
      "     San Jose, CA, 1993.\n",
      "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
      "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
      "     July-August 1995.\n",
      "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
      "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
      "     163-171.\n"
     ]
    }
   ],
   "source": [
    "print(breast_cancer.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fa95a7",
   "metadata": {},
   "source": [
    "---\n",
    "### (4) train, test 데이터 분리\n",
    "---\n",
    "\n",
    "- 모델 학습과 테스트용 문제지와 정답지를 준비해보자.\n",
    "    - `train_test_split` 함수를 사용하여 Data를 학습 : 테스트의 비율을 8:2로 골고루 섞이도록 나눠보자\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6d64748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(455, 30) (455,)\n",
      "(114, 30) (114,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(breast_cancer_data, \n",
    "                                                    breast_cancer_label, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=2222)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab04bd8",
   "metadata": {},
   "source": [
    "- 아래 셀의 결과를 확인하면 나누어진 Test Data가 전체 Data에서 골고루 섞여져 있는 것으로 확인된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60d20297",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 44, 1: 70}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique, counts = np.unique(y_test, return_counts=True)\n",
    "dict(zip(unique, counts))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06442b1",
   "metadata": {},
   "source": [
    "---\n",
    "### (5) 다양한 모델로 학습시켜보기\n",
    "---\n",
    "\n",
    "- 1) **Decision Tree** 사용해 보기<br>\n",
    "- 2) **Random Forest** 사용해 보기<br>\n",
    "- 3) **SVM** 사용해 보기<br>\n",
    "- 4) **SGD Classifier** 사용해 보기<br>\n",
    "- 5) **Logistic Regression** 사용해 보기<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39e7754f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습모델 불러오기 \n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "102502c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습모델을 각각의 변수에 저장\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(random_state=2222)\n",
    "random_forest = RandomForestClassifier(random_state=2222)\n",
    "svm_model = svm.SVC()\n",
    "sgd_model = SGDClassifier()\n",
    "logistic_model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e886d574",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 각각의 모델을 Train Data set로 학습\n",
    "\n",
    "decision_tree.fit(X_train, y_train)\n",
    "random_forest.fit(X_train, y_train)\n",
    "svm_model.fit(X_train, y_train)\n",
    "sgd_model.fit(X_train, y_train)\n",
    "logistic_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "31dcd0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Data를 통해 학습모델의 결과값 예측\n",
    "\n",
    "prediction_decision_tree = decision_tree.predict(X_test)\n",
    "prediction_random_forest = random_forest.predict(X_test)\n",
    "prediction_svm_model = svm_model.predict(X_test)\n",
    "prediction_sgd_model = sgd_model.predict(X_test)\n",
    "prediction_logistic_model = logistic_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cae46c1",
   "metadata": {},
   "source": [
    "---\n",
    "### (6) 모델을 평가해 보기\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c683ef",
   "metadata": {},
   "source": [
    "- **1) sklearn.metrics accuracy 지표를 사용한 경우**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "98710ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8947368421052632\n",
      "0.9298245614035088\n",
      "0.9035087719298246\n",
      "0.8771929824561403\n",
      "0.9298245614035088\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, prediction_decision_tree))\n",
    "print(accuracy_score(y_test, prediction_random_forest))\n",
    "print(accuracy_score(y_test, prediction_svm_model))\n",
    "print(accuracy_score(y_test, prediction_sgd_model))\n",
    "print(accuracy_score(y_test, prediction_logistic_model))\n",
    "# print(accuracy_score(y_test, [1]*len(prediction_logistic_model)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34621f47",
   "metadata": {},
   "source": [
    "- **2) sklearn.metrics classification_report 지표를 사용한 경우**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0511e122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.77      0.85        44\n",
      "           1       0.87      0.97      0.92        70\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.91      0.87      0.88       114\n",
      "weighted avg       0.90      0.89      0.89       114\n",
      "------------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.82      0.90        44\n",
      "           1       0.90      1.00      0.95        70\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.95      0.91      0.92       114\n",
      "weighted avg       0.94      0.93      0.93       114\n",
      "------------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.75      0.86        44\n",
      "           1       0.86      1.00      0.93        70\n",
      "\n",
      "    accuracy                           0.90       114\n",
      "   macro avg       0.93      0.88      0.89       114\n",
      "weighted avg       0.92      0.90      0.90       114\n",
      "------------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.93      0.85        44\n",
      "           1       0.95      0.84      0.89        70\n",
      "\n",
      "    accuracy                           0.88       114\n",
      "   macro avg       0.87      0.89      0.87       114\n",
      "weighted avg       0.89      0.88      0.88       114\n",
      "------------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91        44\n",
      "           1       0.94      0.94      0.94        70\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.93      0.93      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, prediction_decision_tree), end='------------------------------------------------------------\\n\\n')\n",
    "print(classification_report(y_test, prediction_random_forest), end='------------------------------------------------------------\\n\\n')\n",
    "print(classification_report(y_test, prediction_svm_model), end='------------------------------------------------------------\\n\\n')\n",
    "print(classification_report(y_test, prediction_sgd_model), end='------------------------------------------------------------\\n\\n')\n",
    "print(classification_report(y_test, prediction_logistic_model), end='------------------------------------------------------------\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa757bf",
   "metadata": {},
   "source": [
    "- **3) sklearn.metrics confusion_matrix 지표를 사용한 경우**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cef4922b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[34 10]\n",
      " [ 2 68]]\n",
      "\n",
      "[[36  8]\n",
      " [ 0 70]]\n",
      "\n",
      "[[33 11]\n",
      " [ 0 70]]\n",
      "\n",
      "[[41  3]\n",
      " [11 59]]\n",
      "\n",
      "[[40  4]\n",
      " [ 4 66]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, prediction_decision_tree), end='\\n\\n')\n",
    "print(confusion_matrix(y_test, prediction_random_forest), end='\\n\\n')\n",
    "print(confusion_matrix(y_test, prediction_svm_model), end='\\n\\n')\n",
    "print(confusion_matrix(y_test, prediction_sgd_model), end='\\n\\n')\n",
    "print(confusion_matrix(y_test, prediction_logistic_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d49b5d",
   "metadata": {},
   "source": [
    "---\n",
    "### (7) 결론\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cc2ad6",
   "metadata": {},
   "source": [
    "- `프로젝트(3) load_breast_cancer : 유방암 여부를 진단해 봅시다`에서는 569개의 데이터 샘플을 가지고 총 30개의 feature(특징값)를 사용하여 유방암 인지 아닌지 여부를 맞추기위한 **지도학습 - 분류 문제**라 할 수 있다.  \n",
    "\n",
    "\n",
    "- 총 569개의 Data Sample 중 필자는 train_test_split 함수를 이용하여 Data Sample을 8:2 비율로 균등하게 나누었다. 아래 그림과 같이 Data Sample의 데이터들의 치우침 정도를 확인하기 위해 pandas DataFrame의 매소드 value_counts()를 사용하였다.<br> **※ 데이터가 불균형(imbalance) 하지 않음을 확인하였다**\n",
    "\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/103712369/165586850-bbd88d7a-bb33-477b-9d00-65937f240ad5.png)\n",
    "\n",
    "\n",
    "- 본 노드를 통해 배운 Scikit-Learn에서 제공하는 평가지표 함수는 accuracy / classification_report / confusion_matrix가 있었는데 confusion_matrix의 성능지표 중 가장 많이 사용되는 Precision / Recall을 사용하기에는 데이터가 고루 분포되어 있기 때문에 **Accuracy 성능지표를 사용하여 학습모델을 평가하는것이 바람직하다고 생각된다.**\n",
    "\n",
    "\n",
    "- 모델은 **Ensemble 기법 중 하나인 RandomForestClassifier 및 선형 모델의 LogisticRegression**을 사용했을 때 약 93%로 가장 좋은 성능을 보였다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72386a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
