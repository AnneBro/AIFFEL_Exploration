{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00ebd63d",
   "metadata": {},
   "source": [
    "# [E-07] 프로젝트: 뉴스기사 요약해보기\n",
    "\n",
    "<br>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89500d61",
   "metadata": {},
   "source": [
    "**뉴스기사 데이터셋에 대해 추상적 / 추출적 요약을 모두 진행해보자**\n",
    "\n",
    "<br>\n",
    "- 주요 라이브러리 버전 확인\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8f71ce0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.5\n",
      "2.6.0\n",
      "1.2.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "import nltk\n",
    "import tensorflow\n",
    "import summa\n",
    "\n",
    "print(nltk.__version__)\n",
    "print(tensorflow.__version__)\n",
    "print(version('summa'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9870d853",
   "metadata": {},
   "source": [
    "### ✔️ 필요한 라이브러리 import하기\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30f2f2d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /aiffel/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import urllib.request\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='bs4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd14becb",
   "metadata": {},
   "source": [
    "### ✔️ 데이터 수집하기\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4b67124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(98401, 2)\n",
      "Index(['headlines', 'text'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/sunnysai12345/News_Summary/master/news_summary_more.csv\", filename=\"news_summary_more.csv\")\n",
    "data = pd.read_csv('news_summary_more.csv', encoding='iso-8859-1')\n",
    "print(data.shape)\n",
    "print(data.columns)\n",
    "\n",
    "data=data[['text', 'headlines']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cb2effc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>headlines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>79798</th>\n",
       "      <td>Sachin Tendulkar, while wishing former Austral...</td>\n",
       "      <td>Sachin recollects how Lillee made him give up ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33159</th>\n",
       "      <td>Former Finance Minister P Chidambaram on Monda...</td>\n",
       "      <td>Unemployment to be main issue in 2019 LS polls...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16387</th>\n",
       "      <td>Isha Ambani, daughter of Reliance Industries C...</td>\n",
       "      <td>What is the net worth of Isha Ambani and Anand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62193</th>\n",
       "      <td>A former British jihadi bride who married the ...</td>\n",
       "      <td>Racism in Britain forced me to join ISIS: Ex-j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24641</th>\n",
       "      <td>The Centre on Monday confirmed that, according...</td>\n",
       "      <td>Groundwater where Sterlite plant located conta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6374</th>\n",
       "      <td>The Central Bureau of Investigation (CBI) that...</td>\n",
       "      <td>CCTV footage was not tampered: CBI on Jiah Kha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72233</th>\n",
       "      <td>Switzerland President Doris Leuthard during he...</td>\n",
       "      <td>Will support India's fight against black money...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95409</th>\n",
       "      <td>The UK passport could turn dark blue again aft...</td>\n",
       "      <td>UK passports could turn dark blue again after ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84458</th>\n",
       "      <td>A Spanish bullfighter died on Saturday after h...</td>\n",
       "      <td>Spanish bullfighter killed after tripping on cape</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41205</th>\n",
       "      <td>The Supreme Court will hear pleas relating to ...</td>\n",
       "      <td>SC to hear pleas relating to CBSE Board re-exa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "79798  Sachin Tendulkar, while wishing former Austral...   \n",
       "33159  Former Finance Minister P Chidambaram on Monda...   \n",
       "16387  Isha Ambani, daughter of Reliance Industries C...   \n",
       "62193  A former British jihadi bride who married the ...   \n",
       "24641  The Centre on Monday confirmed that, according...   \n",
       "6374   The Central Bureau of Investigation (CBI) that...   \n",
       "72233  Switzerland President Doris Leuthard during he...   \n",
       "95409  The UK passport could turn dark blue again aft...   \n",
       "84458  A Spanish bullfighter died on Saturday after h...   \n",
       "41205  The Supreme Court will hear pleas relating to ...   \n",
       "\n",
       "                                               headlines  \n",
       "79798  Sachin recollects how Lillee made him give up ...  \n",
       "33159  Unemployment to be main issue in 2019 LS polls...  \n",
       "16387  What is the net worth of Isha Ambani and Anand...  \n",
       "62193  Racism in Britain forced me to join ISIS: Ex-j...  \n",
       "24641  Groundwater where Sterlite plant located conta...  \n",
       "6374   CCTV footage was not tampered: CBI on Jiah Kha...  \n",
       "72233  Will support India's fight against black money...  \n",
       "95409  UK passports could turn dark blue again after ...  \n",
       "84458  Spanish bullfighter killed after tripping on cape  \n",
       "41205  SC to hear pleas relating to CBSE Board re-exa...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 98401개의 뉴스 기사 중 10개의 랜덤한 기사를 출력해보고 데이터를 제대로 불러왔는지 확인해보자\n",
    "\n",
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c00b7d",
   "metadata": {},
   "source": [
    "<br>\n",
    "- 추상적 요약을 하는 경우 text를 본문, headlines를 이미 요약된 데이터로 삼아서 모델을 학습한다.\n",
    "<br><br>\n",
    "- 추출적 야약을 하는 경우에는 오직 text 열만을 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb43e66",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "# Ⅰ. 추상적 요약\n",
    "\n",
    "---\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f7f277",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### ✔️ Step 1. 데이터 전처리하기\n",
    "#### (1) 데이터 정리하기\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a54cc43",
   "metadata": {},
   "source": [
    "**⭐ 1) 중복 샘플과 NULL 값이 존재하는 샘플 제거<br>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fb9fc57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "수집된 뉴스기사 샘플의 수 : 98401\n",
      "text 열에서 중복을 배제한 유일한 샘플의 수 : 98360\n",
      "headlines 열에서 중복을 배제한 유일한 샘플의 수 : 98280\n"
     ]
    }
   ],
   "source": [
    "print('수집된 뉴스기사 샘플의 수 :', len(data))\n",
    "print('text 열에서 중복을 배제한 유일한 샘플의 수 :', data['text'].nunique())\n",
    "print('headlines 열에서 중복을 배제한 유일한 샘플의 수 :', data['headlines'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee16d8a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Warne produced 'ball of century' with his 1st Ashes delivery         3\n",
       "Indian spinner once bowled record 21 maiden overs in a row           3\n",
       "Don Bradman once scored 100 runs in 3 overs                          3\n",
       "CARS24 enables car owners to sell their cars in less than 2 hours    3\n",
       "A solar eclipse once proved Einstein right, Newton wrong             3\n",
       "                                                                    ..\n",
       "Xiaomi files for world's biggest IPO since Alibaba in 2014           1\n",
       "Wife of automobile inventor made the world's first road trip         1\n",
       "Punished for serving the country: Ex-Pak PM Nawaz Sharif             1\n",
       "NASA prepares a new set of twin satellites to track ice melt         1\n",
       "Madhesi Morcha withdraws support to Nepalese government              1\n",
       "Name: headlines, Length: 98280, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['headlines'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6835e269",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- 기사의 원문인 `text`열에서는 41개의 중복된 기사기 존재하고, 요약본인 `headlines`열에서는 121개의 중복된 요약이 존재한다.<br><br>\n",
    "- `drop_duplicates()` 매서드를 사용해서 `text`열의 중복된 기사원본을 제거하도록 한다.<br><br>\n",
    "- `headlines`의 경우는 기사가 유사한 내용을 다루고 있는 경우, 중복된 요약을 할 수 있을 것으로 간주하여 중복된 요약은 그대로 두기로 한다.<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42babcae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 98360\n"
     ]
    }
   ],
   "source": [
    "# inplace=True 를 설정하면 DataFrame 타입 값을 return 하지 않고 data 내부를 직접적으로 바꾼다.\n",
    "\n",
    "data.drop_duplicates(subset=['text'], inplace=True)\n",
    "print('전체 샘플수 :', len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a743de6a",
   "metadata": {},
   "source": [
    "<br>\n",
    "- 중복된 샘픙을 제거하였음에도 결측 샘플데이터에 대한 전처리또한 진행해주어야 한다.<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb27016a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text         0\n",
      "headlines    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05044935",
   "metadata": {},
   "source": [
    "<br>\n",
    "- 결측 샘플데이터는 없으므로 중복된 기사 및 결측 데이터 전치리를 마무리한다.<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d41463",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "**⭐ 2) 텍스트 정규화와 불용어 제거**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe79a905",
   "metadata": {},
   "source": [
    "**※ 텍스트 정규화란 ?**\n",
    "- 같은 의미인데 다른 표현으로 사용된 단어들을 정리해주는 것.\n",
    "- ex) `it'll == it will`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3282f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정규화 사전의 수:  120\n"
     ]
    }
   ],
   "source": [
    "contractions = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}\n",
    "\n",
    "print(\"정규화 사전의 수: \", len(contractions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74c9d74",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- 앞서 노드에서 정의해 두었던 정규화 사전을 사용하도록 한다.<br><br>\n",
    "- **불용어(stopwords)**라고 불리는 일반적으로 텍스트에 자주 등장하지만 자연어 처리할 때 실질적으로 도움이 되지 않는 단어들을 제거해야함.<br><br>\n",
    "    - `NLTK`에서 제공하는 불용어 리스트를 참조해, 샘플에서 불용어를 제거한다.<br><br>\n",
    "    - 추가적으로 모든 영어 문자는 소문자로, 섞여있는 html 태그를 제거하고, 정규 표현식을 통해 각종 특수문자를 제거해서 정말 필요한 내용만 잘 학습할 수 있도록 처리해야 함.<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85a734d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "불용어 갯수 : 179\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print('불용어 갯수 :', len(stopwords.words('english')))\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24d8fb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리 정제 함수\n",
    "\n",
    "def preprocess_sentence(sentence, remove_stopwords=True):\n",
    "    sentence = sentence.lower() # 텍스트 소문자화\n",
    "    sentence = BeautifulSoup(sentence, 'lxml').text # <br />, <a href = ...>등의 html 태그 제거\n",
    "    sentence = re.sub(r'\\([^)]*\\)', '', sentence) # 괄호로 닫힌 문자열 (...) 제거 Ex) my husband (and myself!) for => my husband for\n",
    "    sentence = re.sub('\"','', sentence) # 쌍따옴표 \" 제거\n",
    "    sentence = ' '.join([contractions[t] if t in contractions else t for t in sentence.split(\" \")]) # 약어 정규화\n",
    "    sentence = re.sub(r\"'s\\b\",\"\", sentence) # 소유격 제거. Ex) roland's -> roland\n",
    "    sentence = re.sub(\"[^a-zA-Z]\", \" \", sentence) # 영어 외 문자(숫자, 특수문자 등) 공백으로 변환\n",
    "    sentence = re.sub('[m]{2,}', 'mm', sentence) # m이 3개 이상이면 2개로 변경. Ex) ummmmmmm yeah -> umm yeah\n",
    "    \n",
    "    # 불용어 제거 (Text)\n",
    "    if remove_stopwords:\n",
    "        tokens = ' '.join(word for word in sentence.split() if not word in stopwords.words('english') if len(word) > 1)\n",
    "    # 불용어 미제거 (Summary)\n",
    "    else:\n",
    "        tokens = ' '.join(word for word in sentence.split() if len(word) > 1)\n",
    "    return tokens\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c6a1242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 % complete.\n",
      "9.15 % complete.\n",
      "18.3 % complete.\n",
      "27.45 % complete.\n",
      "36.6 % complete.\n",
      "45.75 % complete.\n",
      "54.9 % complete.\n",
      "64.05 % complete.\n",
      "73.2 % complete.\n",
      "82.35 % complete.\n",
      "91.5 % complete.\n",
      "\n",
      "text 전처리 후 결과 : ['saurav kant alumnus upgrad iiit pg program machine learning artificial intelligence sr systems engineer infosys almost years work experience program upgrad degree career support helped transition data scientist tech mahindra salary hike upgrad online power learning powered lakh careers', 'kunal shah credit card bill payment platform cred gave users chance win free food swiggy one year pranav kaushik delhi techie bagged reward spending cred coins users get one cred coin per rupee bill paid used avail rewards brands like ixigo bookmyshow ubereats cult fit', 'new zealand defeated india wickets fourth odi hamilton thursday win first match five match odi series india lost international match rohit sharma captaincy consecutive victories dating back march match witnessed india getting seventh lowest total odi cricket history', 'aegon life iterm insurance plan customers enjoy tax benefits premiums paid save taxes plan provides life cover age years also customers options insure critical illnesses disability accidental death benefit rider life cover age years', 'speaking sexual harassment allegations rajkumar hirani sonam kapoor said known hirani many years true metoo movement get derailed metoo movement always believe woman case need reserve judgment added hirani accused assistant worked sanju']\n"
     ]
    }
   ],
   "source": [
    "clean_text = []\n",
    "# 전체 text 데이터에 대한 전처리\n",
    "for i, s in enumerate(data['text']):\n",
    "    clean_text.append(preprocess_sentence(s))\n",
    "    if i % 9000 == 0:\n",
    "        print(f\"{round(100*i/len(data['text']),2)} % complete.\")\n",
    "    \n",
    "# 전처리 후 출력\n",
    "print('\\ntext 전처리 후 결과 :', clean_text[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "652a1bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 % complete.\n",
      "9.15 % complete.\n",
      "18.3 % complete.\n",
      "27.45 % complete.\n",
      "36.6 % complete.\n",
      "45.75 % complete.\n",
      "54.9 % complete.\n",
      "64.05 % complete.\n",
      "73.2 % complete.\n",
      "82.35 % complete.\n",
      "91.5 % complete.\n",
      "\n",
      "headlines 전처리 후 결과 : ['upgrad learner switches career ml al salary hike', 'delhi techie wins free food swiggy one year cred', 'new zealand end rohit sharma led india match winning streak', 'aegon life iterm insurance plan helps customers save tax', 'known hirani yrs metoo claims true sonam']\n"
     ]
    }
   ],
   "source": [
    "clean_headlines = []\n",
    "# 전체 text 데이터에 대한 전처리\n",
    "for i, s in enumerate(data['headlines']):\n",
    "    clean_headlines.append(preprocess_sentence(s))\n",
    "    if i % 9000 == 0:\n",
    "        print(f\"{round(100*i/len(data['headlines']),2)} % complete.\")\n",
    "    \n",
    "# 전처리 후 출력\n",
    "print('\\nheadlines 전처리 후 결과 :', clean_headlines[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b71803",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- 텍스트 정제의 과정을 거친 후 다시 한번 빈(empty) 샘플이 생겼는지 확인해보자.<br>왜냐하면, 정제 전에는 데이터가 존재했지만, 정제 과정에서 문장의 모든 단어가 사라지는 경우가 있을 수 있다.<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65bae145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정제된 리스트 객체들을 다시 data 데이터프레임으로 재 저장한다.\n",
    "\n",
    "data['text'] = clean_text\n",
    "data['headlines'] = clean_headlines\n",
    "\n",
    "# 빈 값을 null 값으로 변환\n",
    "data.replace('', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3351226",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text         0\n",
       "headlines    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data 내에 null 값이 있는지 확인한다.\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d84089d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 수 : 98360\n"
     ]
    }
   ],
   "source": [
    "data.dropna(axis=0, inplace=True)\n",
    "print('전체 샘플 수 :', len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58439aa",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "**⭐ 3) 샘플의 최대 길이 정하기**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc860b27",
   "metadata": {},
   "source": [
    "- 필요없는 단어를 모두 솎아낸 데이터를 가지게 되었다. 이제는 훈련에 사용할 샘플의 최대 길이를 지정해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33a4b55c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "텍스트의 최소 길이 : 1\n",
      "텍스트의 최대 길이 : 60\n",
      "텍스트의 평균 길이 : 35.09968483123221\n",
      "헤드라인의 최소 길이 : 1\n",
      "헤드라인의 최대 길이 : 13\n",
      "헤드라인의 평균 길이 : 7.136183407889386\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEWCAYAAACnlKo3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAf2ElEQVR4nO3dfbheVX3m8e9NULSKAhJzxYR4gkYtWokQEUd0UCpEsAU7ykurRKSkVCg4VTvBWmGw1DhWrLaWGkskWAQZEUklijEFqaNAAqSEFxkChCFpSCIBAtJGE+75Y68jm8M5J092zvM858m5P9e1r7P3b7+tRU7yY6+99lqyTURERBO7dLsAERHRu5JEIiKisSSRiIhoLEkkIiIaSxKJiIjGkkQiIqKxJJGIiGgsSSSizSStkvTbo+U6ESMpSSQiIhpLEoloI0lfB6YA/yzpCUl/JulgST+R9Kikf5N0aDn2v0j6uaR9yvb+kh6R9JrBrtOtOkXUKcOeRLSXpFXAH9r+oaRJwG3AB4DvA4cBlwGvsb1B0nnAm4GjgJuAr9j+u4HX6XwtIgaXJ5GIzno/sMj2IttP2V4MLAOOLPvPAV5MlUDWAF/uSikjWpQkEtFZLwfeV5qyHpX0KHAIMBHA9q+Ai4DXAZ93mgpilNu12wWIGAPqieBB4Ou2TxnswNLcdTbwNeDzkt5oe/Mg14kYFfIkEtF+64B9y/o/Ab8j6QhJ4yQ9T9KhkiZLEtVTyIXAycBa4NNDXCdiVEgSiWi/zwCfLE1XxwFHA58ANlA9mXyc6u/iGcBLgb8ozVgnASdJeuvA60j6WGerEDG49M6KiIjG8iQSERGNJYlERERjSSIREdFYkkhERDQ25r4T2Xvvvd3X19ftYkRE9JSbb77557bHD4yPuSTS19fHsmXLul2MiIieIumBweJpzoqIiMaSRCIiorEkkYiIaCxJJCIiGksSiYiIxpJEIiKisSSRiIhoLEkkIiIaSxKJiIjG2vbFuqR9gIuBCVTTes6z/UVJewHfBPqAVcCxth8ps7p9ETgSeBL4oO1byrVmAZ8sl/5L2wtK/ECqmeCeDywCzsyc1BHP1jfn6mH3r5p7VIdKEjubdj6JbAE+ans/4GDgNEn7AXOAJbanAUvKNsC7gGllmQ1cAFCSztnAm4CDgLMl7VnOuQA4pXbezDbWJyIiBmhbErG9tv9JwvbjwF3AJKqpQReUwxYAx5T1o4GLXbkB2EPSROAIYLHtjbYfARYDM8u+F9m+oTx9XFy7VkREdEBH3olI6gPeANwITLC9tux6iKq5C6oE82DttNUlNlx89SDxwe4/W9IyScs2bNiwY5WJiIhfa3sSkfRC4ArgI7Y31feVJ4i2v8OwPc/2DNszxo9/1kjGERHRUFuTiKTnUCWQS2x/u4TXlaYoys/1Jb4G2Kd2+uQSGy4+eZB4RER0SNuSSOltdSFwl+3za7sWArPK+izgqlr8RFUOBh4rzV7XAIdL2rO8UD8cuKbs2yTp4HKvE2vXioiIDmjnpFRvAT4ArJC0vMQ+AcwFLpd0MvAAcGzZt4iqe+9Kqi6+JwHY3ijp08DScty5tjeW9Q/zdBff75UlIiI6pG1JxPaPAQ2x+7BBjjdw2hDXmg/MHyS+DHjdDhQzIiJ2QL5Yj4iIxpJEIiKisSSRiIhoLEkkIiIaSxKJiIjGkkQiIqKxJJGIiGgsSSQiIhpLEomIiMaSRCIiorEkkYiIaCxJJCIiGksSiYiIxpJEIiKisSSRiIhoLEkkIiIaa+f0uPMlrZd0ey32TUnLy7Kqf8ZDSX2S/qO27x9q5xwoaYWklZK+VKbCRdJekhZLuqf83LNddYmIiMG180nkImBmPWD7ONvTbU8HrgC+Xdt9b/8+26fW4hcApwDTytJ/zTnAEtvTgCVlOyIiOqhtScT29cDGwfaVp4ljgUuHu4akicCLbN9Qps+9GDim7D4aWFDWF9TiERHRId16J/JWYJ3te2qxqZJulfQjSW8tsUnA6toxq0sMYILttWX9IWBCW0scERHPsmuX7nsCz3wKWQtMsf2wpAOB70h6basXs21JHmq/pNnAbIApU6Y0LHJERAzU8ScRSbsCvwd8sz9me7Pth8v6zcC9wKuANcDk2umTSwxgXWnu6m/2Wj/UPW3Psz3D9ozx48ePZHUiIsa0bjRn/TbwM9u/bqaSNF7SuLK+L9UL9PtKc9UmSQeX9ygnAleV0xYCs8r6rFo8IiI6pJ1dfC8Ffgq8WtJqSSeXXcfz7BfqbwNuK11+vwWcarv/pfyHgX8EVlI9oXyvxOcC75R0D1VimtuuukRExODa9k7E9glDxD84SOwKqi6/gx2/DHjdIPGHgcN2rJQREbEj8sV6REQ0liQSERGNJYlERERjSSIREdFYkkhERDSWJBIREY0liURERGPdGjsrIrZT35yrh9y3au5RHSxJxNPyJBIREY0liURERGNJIhER0ViSSERENJYkEhERjSWJREREY0kiERHRWJJIREQ0liQSERGNtXN63PmS1ku6vRY7R9IaScvLcmRt31mSVkq6W9IRtfjMElspaU4tPlXSjSX+TUnPbVddIiJicNtMIpLeJ2n3sv5JSd+WdEAL174ImDlI/Au2p5dlUbnuflRzr7+2nPP3ksZJGgd8GXgXsB9wQjkW4LPlWq8EHgFOHnijiIhor1aeRP7C9uOSDgF+G7gQuGBbJ9m+HtjYYjmOBi6zvdn2/cBK4KCyrLR9n+1fApcBR0sS8A7gW+X8BcAxLd4rIiJGSCtJZGv5eRQwz/bVwI40HZ0u6bbS3LVniU0CHqwds7rEhoq/BHjU9pYB8UFJmi1pmaRlGzZs2IGiR0REXStJZI2krwDHAYsk7dbieYO5AHgFMB1YC3y+4XW2i+15tmfYnjF+/PhO3DIiYkxoJRkcC1wDHGH7UWAv4ONNbmZ7ne2ttp8CvkrVXAWwBtindujkEhsq/jCwh6RdB8QjIqKDtplEbD8JrAcOKaEtwD1NbiZpYm3zPUB/z62FwPGSdpM0FZgG3AQsBaaVnljPpXr5vtC2gWuB95bzZwFXNSlTREQ0t81JqSSdDcwAXg18DXgO8E/AW7Zx3qXAocDeklYDZwOHSpoOGFgF/BGA7TskXQ7cSZWkTrO9tVzndKonoXHAfNt3lFv8D+AySX8J3Er1wj8iIjqolZkN3wO8AbgFwPa/93f5HY7tEwYJD/kPve3zgPMGiS8CFg0Sv4+nm8MiIqILWnkn8svSfGQASS9ob5EiIqJXtJJELi+9s/aQdArwQ6qX4hERMcZtsznL9l9Leiewieq9yKdsL257ySIiYtRr5Z0IJWkkcURExDMMmUQkPU55DzJwF2DbL2pbqSIioicMmURsb7MHVkREjG0tNWeVUXsPoXoy+bHtW9taqogYNfrmXD3s/lVzj+pQSWI0amUo+E9RjZL7EmBv4CJJn2x3wSIiYvRr5UnkD4D9bf8ngKS5wHLgL9tYroiI6AGtfCfy78Dzatu7kcEOIyKC1p5EHgPukLSY6p3IO4GbJH0JwPYZbSxfRESMYq0kkSvL0u+69hQlIiJ6TStfrC/oREEiIqL3tNI7692SbpW0UdImSY9L2tSJwkVExOjWSnPW3wC/B6woo/lGREQArfXOehC4PQkkIiIGauVJ5M+ARZJ+BGzuD9o+f7iTJM0H3g2st/26Evsc8DvAL4F7gZNsPyqpD7gLuLucfoPtU8s5BwIXAc+nmpzqTNuWtBfwTaCPapbEY20/0kJ9IiJihLTyJHIe8CTVtyK715ZtuQiYOSC2GHid7dcD/xc4q7bvXtvTy3JqLX4BcArVvOvTatecAyyxPQ1YUrYjIqKDWnkSeVn/k8T2sH19ecKox35Q27wBeO9w15A0EXiR7RvK9sXAMcD3gKOp5nCHaliW66jmXY+IiA5p5UlkkaTD23DvD1Elg35TSy+wH0l6a4lNAlbXjlldYgATbK8t6w8BE4a6kaTZkpZJWrZhw4YRKn5ERLSSRP4Y+L6k/xipLr6S/hzYAlxSQmuBKbbfAPwp8A1JLc9XUp8Dfoj982zPsD1j/PjxO1DyiIioa+VjwxGdV0TSB6leuB/W3+PL9mbKS3vbN0u6F3gV1Rhdk2unT+bpcbvWSZpoe21p9lo/kuWMiIhta+VJBEl7SjpI0tv6lyY3kzSTqrfX79p+shYfL2lcWd+X6gX6faW5apOkgyUJOBG4qpy2EJhV1mfV4hER0SHbfBKR9IfAmVRPAcuBg4GfAu/YxnmXUr343lvSauBsqt5YuwGLq5zw6668bwPOlfQr4CngVNsby6U+zNNdfL/H0+9R5gKXSzoZeAA4tpUKR0TEyGmld9aZwBup/sF/u6TXAH+1rZNsnzBI+MIhjr0CuGKIfcuAZ/UOs/0wcNi2yhEREe3TSnPWf9YmpNrN9s+AV7e3WBER0QtaeRJZLWkP4DtUzVCPUDUfRUTEGNdK76z3lNVzJF0LvBj4fltLFRERPaGVoeBfIWm3/k2qsap+o52FioiI3tDKO5ErgK2SXgnMA/YBvtHWUkVERE9oJYk8ZXsL8B7gb21/HJjY3mJFREQvaCWJ/ErSCVQf9H23xJ7TviJFRESvaCWJnAS8GTjP9v2SpgJfb2+xIiKiF7TSO+tO4Iza9v3AZ9tZqIiI6A0tjZ0VERExmCSRiIhobMgkIunr5eeZnStORET0kuGeRA6U9DLgQ2Uo+L3qS6cKGBERo9dwL9b/AVgC7AvcTPW1ej+XeEREjGFDPonY/pLt3wTm297X9tTakgQSEREtdfH9Y0n7A28toett39beYkVERC9oZQDGM4BLgJeW5RJJf9LugkVExOjXShffPwTeZPtTtj9FNT3uKa1cXNJ8Sesl3V6L7SVpsaR7ys89S1ySviRppaTbJB1QO2dWOf4eSbNq8QMlrSjnfKnMwx4RER3SShIRsLW2vZVnvmQfzkXAzAGxOcAS29OoXtzPKfF3AdPKMhu4AKqkQzU/+5uAg4Cz+xNPOeaU2nkD7xUREW3UShL5GnCjpHMknQPcwBBzpQ9k+3pg44Dw0cCCsr4AOKYWv9iVG4A9JE0EjgAW295o+xFgMTCz7HuR7RtsG7i4dq2IiOiAVl6sny/pOuCQEjrJ9q07cM8JtteW9YeACWV9EvBg7bjVJTZcfPUg8WeRNJvq6YYpU6bsQNEjRqe+OVd3uwgxRrUyxzq2bwFuGemb27Ykj/R1B7nPPKoJtZgxY0bb7xcRMVZ0Y+ysdaUpivJzfYmvoZo1sd/kEhsuPnmQeEREdEg3kshCqgmuKD+vqsVPLL20DgYeK81e1wCHl6FX9gQOB64p+zZJOrj0yjqxdq2IiOiAYZuzJI0Dfmj77U0uLulS4FBgb0mrqXpZzQUul3Qy8ABwbDl8EXAksBJ4kmoyLGxvlPRpYGk57lzb/S/rP0zVA+z5wPfKEhERHTJsErG9VdJTkl5s+7HtvbjtE4bYddggxxo4bYjrzAfmDxJfBrxue8sVEREjo5UX608AKyQtBn7RH7R9xtCnRETEWNBKEvl2WSJiJ5UuwtFUK9+JLJD0fGCK7bs7UKaIiOgRrQzA+DvAcuD7ZXu6pIVtLldERPSAVrr4nkM1ZtWjALaXkwmpIiKC1pLIrwbpmfVUOwoTERG9pZUX63dI+n1gnKRpwBnAT9pbrIiI6AWtPIn8CfBaYDNwKbAJ+EgbyxQRET2ild5ZTwJ/Lumz1aYfb3+xIiKiF7TSO+uNklYAt1F9dPhvkg5sf9EiImK0a+WdyIXAh23/K4CkQ6gmqnp9OwsWERGjXyvvRLb2JxAA2z8GtrSvSBER0SuGfBKRdEBZ/ZGkr1C9VDdwHHBd+4sWERGj3XDNWZ8fsH12bT2zA0ZExNBJpOkcIhERMXZs88W6pD2oZg3sqx+foeAjIqKVF+uLqBLICuDm2tKIpFdLWl5bNkn6iKRzJK2pxY+snXOWpJWS7pZ0RC0+s8RWSprTtEwREdFMK118n2f7T0fqhmU4+enw6+l31wBXUk2H+wXbf10/XtJ+wPFUX82/DPihpFeV3V8G3gmsBpZKWmj7zpEqa0REDK+VJPJ1SacA36Ua+gSo5j4fgfsfBtxr+wFJQx1zNHCZ7c3A/ZJWUo0qDLDS9n0Aki4rxyaJRER0SCvNWb8EPgf8lKebspaN0P2Pp+o63O90SbdJmi9pzxKbBDxYO2Z1iQ0VfxZJsyUtk7Rsw4YNI1T0iIhoJYl8FHil7T7bU8uyw/OJSHou8LvA/y6hC4BXUDV1reXZXYwbsz3P9gzbM8aPHz9Sl42IGPNaac5aCTzZhnu/C7jF9jqA/p8Akr5K1XwG1TuTfWrnTS4xholHREQHtJJEfgEsl3Qtz3wnsqNdfE+g1pQlaaLttWXzPcDtZX0h8A1J51O9WJ8G3AQImCZpKlXyOB74/R0sU0REbIdWksh3yjJiJL2AqlfVH9XC/0vSdKqv4Vf177N9h6TLqV6YbwFOs721XOd04BpgHDDf9h0jWc6IiBheK/OJLBjpm9r+BfCSAbEPDHP8ecB5g8QXUX3HEhERXdDKF+v3M8hYWSPxcj0iInpbK81ZM2rrzwPeB+zVnuJEREQv2WYXX9sP15Y1tv8GOKr9RYuIiNGuleasA2qbu1A9mbTyBBMRETu5VpJB/aO/LVQ9p45tS2kiIqKntNI7K/OKRETEoFppztoN+G88ez6Rc9tXrIiI6AWtNGddBTxGNfDi5m0cGxERY0grSWSy7ZltL0lERPScVkbx/Ymk32p7SSIioue08iRyCPDB8uX6ZqqBD2379W0tWUREjHqtJJF3tb0UERHRk1rp4vtAJwoSMdb1zbm620WI2G6tvBOJiIgYVJJIREQ0liQSERGNJYlERERjXUsiklZJWiFpuaRlJbaXpMWS7ik/9yxxSfqSpJWSbquPLCxpVjn+HkmzulWfiIixqNtPIm+3Pd12/8RXc4AltqcBS8o2VN2Mp5VlNnABVEkHOBt4E3AQcHZ/4omIiPbrdhIZ6Gigf073BcAxtfjFrtwA7CFpInAEsNj2RtuPAIuBDNESEdEh3ZxcysAPJBn4iu15wATba8v+h4AJZX0S8GDt3NUlNlT8GSTNpnqCYcqUKSNZh4gYxra+fVk1N5Ok9rpuJpFDbK+R9FJgsaSf1XfadkkwO6wkqHkAM2bMGJFrRkREF5uzbK8pP9cDV1K901hXmqkoP9eXw9cA+9ROn1xiQ8UjIqIDuvIkIukFwC62Hy/rhwPnAguBWcDc8vOqcspC4HRJl1G9RH/M9lpJ1wB/VXuZfjhwVgerEvEMab6JsaZbzVkTgCsl9ZfhG7a/L2kpcLmkk4EHeHou90XAkcBK4EngJADbGyV9GlhajjvX9sbOVSMiYmzrShKxfR+w/yDxh4HDBokbOG2Ia80H5o90GSOiNRk4cmwbbV18IyKihySJREREY0kiERHRWDe/E4kYc/L+IHY2eRKJiIjGkkQiIqKxJJGIiGgsSSQiIhpLEomIiMaSRCIiorEkkYiIaCxJJCIiGksSiYiIxpJEIiKisSSRiIhoLEkkIiIa63gSkbSPpGsl3SnpDklnlvg5ktZIWl6WI2vnnCVppaS7JR1Ri88ssZWS5nS6LhERY103RvHdAnzU9i2SdgdulrS47PuC7b+uHyxpP+B44LXAy4AfSnpV2f1l4J3AamCppIW27+xILSIiovNJxPZaYG1Zf1zSXcCkYU45GrjM9mbgfkkrgYPKvpVlql0kXVaOTRKJiOiQrr4TkdQHvAG4sYROl3SbpPmS9iyxScCDtdNWl9hQ8cHuM1vSMknLNmzYMJJViIgY07qWRCS9ELgC+IjtTcAFwCuA6VRPKp8fqXvZnmd7hu0Z48ePH6nLRkSMeV2Z2VDSc6gSyCW2vw1ge11t/1eB75bNNcA+tdMnlxjDxCMiogO60TtLwIXAXbbPr8Un1g57D3B7WV8IHC9pN0lTgWnATcBSYJqkqZKeS/XyfWEn6hAREZVuPIm8BfgAsELS8hL7BHCCpOmAgVXAHwHYvkPS5VQvzLcAp9neCiDpdOAaYBww3/YdnatGRER0o3fWjwENsmvRMOecB5w3SHzRcOdFRER75Yv1iIhoLEkkIiIaSxKJiIjGkkQiIqKxJJGIiGgsSSQiIhpLEomIiMaSRCIiorGujJ0VEQHQN+fqYfevmntUh0oSTSWJRGyHbf2jFzHWJIlEDJBEMXoM92eRp5TRIe9EIiKisSSRiIhoLEkkIiIaSxKJiIjGkkQiIqKxJJGIiGis55OIpJmS7pa0UtKcbpcnImIs6envRCSNA74MvBNYDSyVtND2nd0tWYxm+Q5k55Cv3UeHnk4iwEHAStv3AUi6DDgaSBIZ45IoIkmmM3o9iUwCHqxtrwbeNPAgSbOB2WXzCUl3t3DtvYGf73AJR4edqS6Q+oxmPVMXfbalw3qmPi3Y0bq8fLBgryeRltieB8zbnnMkLbM9o01F6qidqS6Q+oxmO1NdYOeqT7vq0usv1tcA+9S2J5dYRER0QK8nkaXANElTJT0XOB5Y2OUyRUSMGT3dnGV7i6TTgWuAccB823eM0OW3q/lrlNuZ6gKpz2i2M9UFdq76tKUust2O60ZExBjQ681ZERHRRUkiERHRWJLIAL0+jIqk+ZLWS7q9FttL0mJJ95Sfe3azjK2StI+kayXdKekOSWeWeK/W53mSbpL0b6U+/7PEp0q6sfzOfbN0EukJksZJulXSd8t2L9dllaQVkpZLWlZiPfm7BiBpD0nfkvQzSXdJenM76pMkUlMbRuVdwH7ACZL2626ptttFwMwBsTnAEtvTgCVluxdsAT5qez/gYOC08ufRq/XZDLzD9v7AdGCmpIOBzwJfsP1K4BHg5O4VcbudCdxV2+7lugC83fb02vcUvfq7BvBF4Pu2XwPsT/XnNPL1sZ2lLMCbgWtq22cBZ3W7XA3q0QfcXtu+G5hY1icCd3e7jA3rdRXVOGk9Xx/gN4BbqEZY+Dmwa4k/43dwNC9U32UtAd4BfBdQr9allHcVsPeAWE/+rgEvBu6ndJ5qZ33yJPJMgw2jMqlLZRlJE2yvLesPARO6WZgmJPUBbwBupIfrU5p/lgPrgcXAvcCjtreUQ3rpd+5vgD8DnirbL6F36wJg4AeSbi5DJUHv/q5NBTYAXyvNjf8o6QW0oT5JImOMq/8F6al+3ZJeCFwBfMT2pvq+XquP7a22p1P9X/xBwGu6W6JmJL0bWG/75m6XZQQdYvsAqubs0yS9rb6zx37XdgUOAC6w/QbgFwxouhqp+iSJPNPOOozKOkkTAcrP9V0uT8skPYcqgVxi+9sl3LP16Wf7UeBaqiafPST1f/jbK79zbwF+V9Iq4DKqJq0v0pt1AcD2mvJzPXAlVZLv1d+11cBq2zeW7W9RJZURr0+SyDPtrMOoLARmlfVZVO8WRj1JAi4E7rJ9fm1Xr9ZnvKQ9yvrzqd7v3EWVTN5bDuuJ+tg+y/Zk231Uf0/+xfYf0IN1AZD0Akm7968DhwO306O/a7YfAh6U9OoSOoxqiowRr0++WB9A0pFUbb39w6ic190SbR9JlwKHUg37vA44G/gOcDkwBXgAONb2xi4VsWWSDgH+FVjB0+3un6B6L9KL9Xk9sIDqd2sX4HLb50ral+r/5vcCbgXeb3tz90q6fSQdCnzM9rt7tS6l3FeWzV2Bb9g+T9JL6MHfNQBJ04F/BJ4L3AecRPm9YwTrkyQSERGNpTkrIiIaSxKJiIjGkkQiIqKxJJGIiGgsSSQiIhpLEomdmqQn2nDN6aUreP/2OZI+tgPXe18ZZfXakSlh43KskrR3N8sQvSdJJGL7TQeO3NZB2+Fk4BTbbx/Ba0Z0RJJIjBmSPi5pqaTbanN59JWngK+WOT5+UL4mR9Iby7HLJX1O0u1lJINzgeNK/Lhy+f0kXSfpPklnDHH/E8p8FbdL+myJfQo4BLhQ0ucGHD9R0vXlPrdLemuJXyBpmWpzkpT4Kkmf6Z8PQ9IBkq6RdK+kU8sxh5ZrXq1q3px/kPSsfwckvV/V3CfLJX2lDBw5TtJFpSwrJP33HfwjiZ1Bt4cszpKlnQvwRPl5ODCParjyXaiGLn8b1bD5W4Dp5bjLqb6yhmrYizeX9bmU4fWBDwJ/V7vHOcBPgN2oRgp4GHjOgHK8DPh/wHiqL6L/BTim7LsOmDFI2T8K/HlZHwfsXtb3qsWuA15ftlcBf1zWvwDcBuxe7rmuxA8F/hPYt5y/GHhv7fy9gd8E/rm/DsDfAycCBwKLa+Xbo9t/vlm6v+RJJMaKw8tyK9U8Hq8BppV999teXtZvBvrKGFe72/5piX9jG9e/2vZm2z+nGtRu4BDbbwSus73B1VDpl1AlseEsBU6SdA7wW7YfL/FjJd1S6vJaqgnU+vWP9bYCuNH247Y3AJv7x+0CbrJ9n+2twKVUT0J1h1EljKVl2PrDqJLOfcC+kv5W0kxgEzHm7brtQyJ2CgI+Y/srzwhW85TUx3baCjy/wfUHXmOH/27Zvr4MR34UcJGk86nGEvsY8Ebbj0i6CHjeIOV4akCZnqqVaeBYRwO3BSywfdbAMknaHzgCOBU4FvjQ9tYrdi55Eomx4hrgQ2VuEiRNkvTSoQ52NVT745LeVELH13Y/TtVMtD1uAv6rpL1VTcN8AvCj4U6Q9HKqZqivUg2kdwDwIqq5IR6TNIFq7ovtdVAZqXoX4DjgxwP2LwHe2//fR9W83C8vPbd2sX0F8MlSnhjj8iQSY4LtH0j6TeCn1QjzPAG8n+qpYSgnA1+V9BTVP/iPlfi1wJzS1POZFu+/VtKccq6omr+2NQz3ocDHJf2qlPdE2/dLuhX4GdUsnP+nlfsPsBT4O+CVpTxX1nfavlPSJ6lm+dsF+BVwGvAfVDPl9f/P57OeVGLsySi+EUOQ9ELbT5T1OVRzU5/Z5WLtkPqw7V0uSuwk8iQSMbSjJJ1F9ffkAapeWRFRkyeRiIhoLC/WIyKisSSRiIhoLEkkIiIaSxKJiIjGkkQiIqKx/w/cLTfHCgNRxgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 길이 분포 출력\n",
    "text_len = [len(s.split()) for s in data['text']]\n",
    "headlines_len = [len(s.split()) for s in data['headlines']]\n",
    "\n",
    "print('텍스트의 최소 길이 : {}'.format(np.min(text_len)))\n",
    "print('텍스트의 최대 길이 : {}'.format(np.max(text_len)))\n",
    "print('텍스트의 평균 길이 : {}'.format(np.mean(text_len)))\n",
    "print('헤드라인의 최소 길이 : {}'.format(np.min(headlines_len)))\n",
    "print('헤드라인의 최대 길이 : {}'.format(np.max(headlines_len)))\n",
    "print('헤드라인의 평균 길이 : {}'.format(np.mean(headlines_len)))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.boxplot(text_len)\n",
    "plt.title('text')\n",
    "plt.subplot(122)\n",
    "plt.boxplot(headlines_len)\n",
    "plt.title('headlines')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.title('text')\n",
    "plt.hist(text_len, bins=40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()\n",
    "\n",
    "plt.title('headlines')\n",
    "plt.hist(headlines_len, bins=40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc309c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위 통계적인 데이터 값을 통해 text와 headlines의 최대 길이를 임의로 정해본다.\n",
    "\n",
    "text_max_len = 40\n",
    "headlines_max_len = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0312fdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def below_threshold_len(max_len, nested_list):\n",
    "  cnt = 0\n",
    "  for s in nested_list:\n",
    "    if(len(s.split()) <= max_len):\n",
    "        cnt = cnt + 1\n",
    "  print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (cnt / len(nested_list))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13c5d7fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 중 길이가 40 이하인 샘플의 비율: 0.9238714924766165\n",
      "전체 샘플 중 길이가 8 이하인 샘플의 비율: 0.8925782838552258\n"
     ]
    }
   ],
   "source": [
    "below_threshold_len(text_max_len, data['text'])\n",
    "below_threshold_len(headlines_max_len,  data['headlines'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e86fb15",
   "metadata": {},
   "source": [
    "- 40과 8로 text와 headlines를 각각 패딩하게 되면 해당 길이보다 긴 샘플들은 잘리게 된다.<br>text의 경우 약 8%, headlines의 경우 약 10% 샘플의 내용이 망가지게 된다.<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9989315c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 81914\n"
     ]
    }
   ],
   "source": [
    "data = data[data['text'].apply(lambda x: len(x.split()) <= text_max_len)]\n",
    "data = data[data['headlines'].apply(lambda x: len(x.split()) <= headlines_max_len)]\n",
    "print('전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c61ea8",
   "metadata": {},
   "source": [
    "△ `text`와 `headlines`의 최대길이를 설정하여 최대길이를 넘어서는 샘플은 제외시켰더니, 전체 샘플수는 98360 >>> 81914로 줄었다.<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642a0793",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "**⭐ 4) 시작토큰과 종료토큰 추가하기**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24e59ac",
   "metadata": {},
   "source": [
    "- `seq2seq` 모델 훈련을 위해 디코더의 입력과 레이블에 시작 토큰과 종료 토큰을 추가해야한다.<br>디코더의 입력에 해당하면서 시작 토큰이 맨 앞에 있는 문장의 이름을 `decoder_input`, <br>디코더의 출력 또는 레이블에 해당하면서 종료 토큰이 맨 뒤에 붙는 문장의 이름은 `decoder_target`이라고 이름을 정했다.<br><br>\n",
    "- 우리의 목표인 텍스트 문장을 읽고 요약을 하기위한 것으로 두 문장 모두 `headlines` 열로부터 만들기로 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "48f2d9f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>headlines</th>\n",
       "      <th>decoder_input</th>\n",
       "      <th>decoder_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>saurav kant alumnus upgrad iiit pg program mac...</td>\n",
       "      <td>upgrad learner switches career ml al salary hike</td>\n",
       "      <td>sostoken upgrad learner switches career ml al ...</td>\n",
       "      <td>upgrad learner switches career ml al salary hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>speaking sexual harassment allegations rajkuma...</td>\n",
       "      <td>known hirani yrs metoo claims true sonam</td>\n",
       "      <td>sostoken known hirani yrs metoo claims true sonam</td>\n",
       "      <td>known hirani yrs metoo claims true sonam eostoken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>india recorded lowest odi total new zealand ge...</td>\n",
       "      <td>india get lowest odi total new zealand</td>\n",
       "      <td>sostoken india get lowest odi total new zealand</td>\n",
       "      <td>india get lowest odi total new zealand eostoken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>weeks ex cbi director alok verma told departme...</td>\n",
       "      <td>govt directs alok verma join work day retirement</td>\n",
       "      <td>sostoken govt directs alok verma join work day...</td>\n",
       "      <td>govt directs alok verma join work day retireme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>congress candidate shafia zubair ramgarh assem...</td>\n",
       "      <td>cong wins ramgarh bypoll rajasthan takes total...</td>\n",
       "      <td>sostoken cong wins ramgarh bypoll rajasthan ta...</td>\n",
       "      <td>cong wins ramgarh bypoll rajasthan takes total...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  saurav kant alumnus upgrad iiit pg program mac...   \n",
       "4  speaking sexual harassment allegations rajkuma...   \n",
       "6  india recorded lowest odi total new zealand ge...   \n",
       "7  weeks ex cbi director alok verma told departme...   \n",
       "9  congress candidate shafia zubair ramgarh assem...   \n",
       "\n",
       "                                           headlines  \\\n",
       "0   upgrad learner switches career ml al salary hike   \n",
       "4           known hirani yrs metoo claims true sonam   \n",
       "6             india get lowest odi total new zealand   \n",
       "7   govt directs alok verma join work day retirement   \n",
       "9  cong wins ramgarh bypoll rajasthan takes total...   \n",
       "\n",
       "                                       decoder_input  \\\n",
       "0  sostoken upgrad learner switches career ml al ...   \n",
       "4  sostoken known hirani yrs metoo claims true sonam   \n",
       "6    sostoken india get lowest odi total new zealand   \n",
       "7  sostoken govt directs alok verma join work day...   \n",
       "9  sostoken cong wins ramgarh bypoll rajasthan ta...   \n",
       "\n",
       "                                      decoder_target  \n",
       "0  upgrad learner switches career ml al salary hi...  \n",
       "4  known hirani yrs metoo claims true sonam eostoken  \n",
       "6    india get lowest odi total new zealand eostoken  \n",
       "7  govt directs alok verma join work day retireme...  \n",
       "9  cong wins ramgarh bypoll rajasthan takes total...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 요약 데이터에는 시작 토큰과 종료 토큰을 추가한다.\n",
    "data['decoder_input'] = data['headlines'].apply(lambda x:'sostoken ' + x)\n",
    "data['decoder_target'] = data['headlines'].apply(lambda x : x + ' eostoken')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "84b05dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더의 입력, 디코더의 입력과 디코더의 레이블을 각각 다시 Numpy 타입으로 저장한다.\n",
    "\n",
    "encoder_input = np.array(data['text'])  # 인코더의 입력\n",
    "decoder_input = np.array(data['decoder_input'])  # 디코더의 입력\n",
    "decoder_target = np.array(data['decoder_target'])  # 디코더의 레이블"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c0c4e2",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- 이제 훈련데이터와 테스트데이터를 분리하는데 직접 코딩을 통해 분리하는 방법을 사용한다.<br>\n",
    "- `encoder_input`과 크기와 형태가 같은 순서가 섞인 정수 시퀀스를 만든다.<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "486adef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9785  1118 17741 ... 73589 42301 28453]\n"
     ]
    }
   ],
   "source": [
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23883fed",
   "metadata": {},
   "source": [
    "- 정수 시퀀스를 통해 다시 데이터의 샘플 순서를 정의해주면 잘 섞인 샘플이 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "136dc04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd800faa",
   "metadata": {},
   "source": [
    "- 이제 섞인 데이터를 8:2 비율로 훈련 데이터와 검증데이터로 분리한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd27aa0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증 데이터의 수 : 16382\n"
     ]
    }
   ],
   "source": [
    "n_of_val = int(len(encoder_input)*0.2)\n",
    "print('검증 데이터의 수 :', n_of_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d10656fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 갯수 : 65532\n",
      "훈련 레이블의 갯수 : 65532\n",
      "검증 데이터의 갯수 : 16382\n",
      "검증 레이블의 갯수 : 16382\n"
     ]
    }
   ],
   "source": [
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]\n",
    "\n",
    "print('훈련 데이터의 갯수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 갯수 :', len(decoder_input_train))\n",
    "print('검증 데이터의 갯수 :', len(encoder_input_test))\n",
    "print('검증 레이블의 갯수 :', len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37fbb08",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "**⭐ 5) 단어집합(vocabulary) 만들기 및 정수 인코딩**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e44431",
   "metadata": {},
   "source": [
    "- 이제 기계가 텍스트를 숫자로 처리할 수 있도록 훈련데이터와 검증데이터의 단어들을 모두 정수로 바꾸어 주어야 한다.<br>이를 위해서 각 단어에 고유한 정수를 맵핑하는 작업이 필요한데 이 과정을 **단어집합(vocabulary)**를 만든다고 표현한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c661508f",
   "metadata": {},
   "source": [
    "#### 5-1) `text` 데이터 정수 인코딩<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c44546af",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_tokenizer = Tokenizer()  # 토크나이저 정의\n",
    "src_tokenizer.fit_on_texts(encoder_input_train)  # 입력된 데이터로부터 단어 집합 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7b60fe78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 62895\n",
      "등장 빈도가 6번 이하인 희귀 단어의 수: 42879\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 20016\n",
      "단어 집합에서 희귀 단어의 비율: 68.17553064631528\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 3.8742576177813994\n"
     ]
    }
   ],
   "source": [
    "threshold = 7\n",
    "total_cnt = len(src_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in src_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30963d8",
   "metadata": {},
   "source": [
    "- `encoder_input_train`에는 6만여개의 단어가 있다.<br>\n",
    "- 등장빈도가 threshold 값이 7회 미만, 즉 6회 이하인 단어들은 단어 집합에서 약 70%를 차지한다. 하지만 실제로 훈련 데이터에서 등장 빈도로 차지하는 비중은 상대적으로 적은 수치인 3.8 밖에 되지 않는다.<br><br>\n",
    "- 따라서, 등장 빈도가 6회 이하인 단어들은 정수 인코딩 과정에서 빼고, 훈련 데이터에서 제거하고자 한다.<br>위에서 이를 제외한 단어 집합의 크기를 어림잡아 20,000으로 제한한다. \n",
    "    - 토크나이저를 정의할 때, `num_words`의 값을 정해주면, 단어 집합의 크기를 제한할 수 있다.<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4a2351f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vocab = 20000\n",
    "src_tokenizer = Tokenizer(num_words=src_vocab)  # 단어 집합의 크기를 20,000으로 제한\n",
    "src_tokenizer.fit_on_texts(encoder_input_train)  # 단어 집합 재생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a1c5f6",
   "metadata": {},
   "source": [
    "- `text_to_sequences()`는 생성된 단어 집합에 기반하여 입력으로 주어진 텍스트 데이터의 단어들을 모두 정수로 변환하는 정수 인코딩을 수행함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "930df316",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_input_train ::\n",
      "[[1161, 222, 180, 14, 134, 45, 59, 17, 614, 1564, 3542, 1161, 105, 1264, 193, 180, 14, 2217, 73, 1254, 1406, 2580, 74, 1, 7, 650, 1674, 614, 3708, 385, 813, 11861, 1118, 602, 14968], [1491, 19, 1242, 1325, 9749, 15698, 656, 730, 1294, 686, 137, 1068, 611, 3594, 15698, 946, 611, 656, 40, 3438, 228, 584, 2449, 404, 357, 10240, 32, 107, 611, 357, 404, 14303, 15698], [469, 7190, 2030, 288, 2680, 140, 37, 1096, 15699, 18618, 658, 405, 171, 28, 1, 469, 3733, 171, 628, 5282, 6185, 288, 657, 37, 16, 224, 140, 37, 493, 22, 7066, 469, 2493, 2208, 1153, 109, 11142, 12739, 5339, 2313]]\n",
      "\n",
      "encoder_input_val ::\n",
      "[[144, 7, 98, 58, 458, 5361, 6640, 444, 2925, 2182, 227, 1694, 74, 1, 98, 458, 186, 4001, 120, 488, 2182, 400, 661, 1, 99, 628, 40, 1331, 186], [4863, 31, 326, 219, 230, 263, 44, 3744, 1722, 9500, 4397, 186, 1322, 317, 2526, 6037, 1322, 1301, 2531, 307, 5482, 1175, 613, 326, 12, 83, 372, 1088, 635, 80, 1288, 280, 306, 543, 5535, 4528], [99, 1443, 3973, 780, 7576, 1095, 1188, 16062, 69, 29, 123, 2866, 52, 1443, 47, 28, 1294, 1127, 16062, 695, 12125, 2633, 10600, 534, 1188, 1188, 4699, 12125, 14039, 2633, 92, 14360]]\n"
     ]
    }
   ],
   "source": [
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "encoder_input_train = src_tokenizer.texts_to_sequences(encoder_input_train)\n",
    "encoder_input_test = src_tokenizer.texts_to_sequences(encoder_input_test)\n",
    "\n",
    "# 잘 진행되었는지 샘플 출력\n",
    "print('encoder_input_train ::')\n",
    "print(encoder_input_train[:3])\n",
    "print('\\nencoder_input_val ::')\n",
    "print(encoder_input_test[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d0f8bb",
   "metadata": {},
   "source": [
    "#### 5-2) `headlines` 데이터 정수 인코딩<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "19b073d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_tokenizer = Tokenizer()\n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "38b0a91b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 27555\n",
      "등장 빈도가 5번 이하인 희귀 단어의 수: 18256\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 9299\n",
      "단어 집합에서 희귀 단어의 비율: 66.25294864815822\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 6.784627587263478\n"
     ]
    }
   ],
   "source": [
    "threshold = 6\n",
    "total_cnt = len(tar_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in tar_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1b9048",
   "metadata": {},
   "source": [
    "- 등장빈도가 5회 이하인 단어들은 단어 집합에서 약 70%를 차지하고 있다. 실제 훈련 데이터에서 등장 빈도로 차지하는 비중은 5.87% 밖에 되지 않는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "65053725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input\n",
      "input  [[1, 924, 504, 49, 9, 127, 838], [1, 318, 1780, 61, 1323, 221], [1, 122, 311, 736, 1277, 5608, 14], [1, 10, 64, 997, 5, 163, 114, 556, 7805], [1, 4, 1109, 84, 3242, 1900, 62, 1045]]\n",
      "target\n",
      "decoder  [[924, 504, 49, 9, 127, 838, 2], [318, 1780, 61, 1323, 221, 2], [122, 311, 736, 1277, 5608, 14, 2], [10, 64, 997, 5, 163, 114, 556, 7805, 2], [4, 1109, 84, 3242, 1900, 62, 1045, 2]]\n"
     ]
    }
   ],
   "source": [
    "tar_vocab = 9000\n",
    "tar_tokenizer = Tokenizer(num_words=tar_vocab) \n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)\n",
    "tar_tokenizer.fit_on_texts(decoder_target_train)\n",
    "\n",
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "decoder_input_train = tar_tokenizer.texts_to_sequences(decoder_input_train) \n",
    "decoder_target_train = tar_tokenizer.texts_to_sequences(decoder_target_train)\n",
    "decoder_input_test = tar_tokenizer.texts_to_sequences(decoder_input_test)\n",
    "decoder_target_test = tar_tokenizer.texts_to_sequences(decoder_target_test)\n",
    "\n",
    "# 잘 변환되었는지 확인\n",
    "print('input')\n",
    "print('input ',decoder_input_train[:5])\n",
    "print('target')\n",
    "print('decoder ',decoder_target_train[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb5e09c",
   "metadata": {},
   "source": [
    "- `decoder_input_train`과 `decoder_target_train`에는 더 이상 숫자 9000이 넘는 숫자들은 존재하지 않는다. <br><br>\n",
    "- 전체 데이터에서 빈도수가 낮은 단어가 삭제되었다 따라서, 빈도수가 낮은 단어만으로 구성되었던 샘플들은 이제 빈(empty)샘플이 되었다.<br>\n",
    "- 헤드라인에서 실제 길이가 1로 나오는 인덱스를 `drop_train`과 `drop_test` 변수에 저장 후 샘플들을 모두 삭제한다.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4db473f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삭제할 훈련 데이터의 개수 : 2\n",
      "삭제할 테스트 데이터의 개수 : 1\n",
      "훈련 데이터의 개수 : 65530\n",
      "훈련 레이블의 개수 : 65530\n",
      "테스트 데이터의 개수 : 16381\n",
      "테스트 레이블의 개수 : 16381\n"
     ]
    }
   ],
   "source": [
    "drop_train = [index for index, sentence in enumerate(decoder_input_train) if len(sentence) == 1]\n",
    "drop_test = [index for index, sentence in enumerate(decoder_input_test) if len(sentence) == 1]\n",
    "\n",
    "print('삭제할 훈련 데이터의 개수 :', len(drop_train))\n",
    "print('삭제할 테스트 데이터의 개수 :', len(drop_test))\n",
    "\n",
    "encoder_input_train = [sentence for index, sentence in enumerate(encoder_input_train) if index not in drop_train]\n",
    "decoder_input_train = [sentence for index, sentence in enumerate(decoder_input_train) if index not in drop_train]\n",
    "decoder_target_train = [sentence for index, sentence in enumerate(decoder_target_train) if index not in drop_train]\n",
    "\n",
    "encoder_input_test = [sentence for index, sentence in enumerate(encoder_input_test) if index not in drop_test]\n",
    "decoder_input_test = [sentence for index, sentence in enumerate(decoder_input_test) if index not in drop_test]\n",
    "decoder_target_test = [sentence for index, sentence in enumerate(decoder_target_test) if index not in drop_test]\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :', len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :', len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :', len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbc0053",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "**⭐ 6) 패딩하기**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff866e9b",
   "metadata": {},
   "source": [
    "- 텍스트 시퀀스를 정수 시퀀스로 변환했다면, 이제 서로 다른 길이의 샘플들을 병렬 처리하기 위해 같은 길이로 맞춰주는 `패딩`작업을 해주어야 한다.\n",
    "- 미리 정해두었던 최대길이로 패딩한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4c71b493",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_train = pad_sequences(encoder_input_train, maxlen=text_max_len, padding='post')\n",
    "encoder_input_test = pad_sequences(encoder_input_test, maxlen=text_max_len, padding='post')\n",
    "decoder_input_train = pad_sequences(decoder_input_train, maxlen=headlines_max_len, padding='post')\n",
    "decoder_target_train = pad_sequences(decoder_target_train, maxlen=headlines_max_len, padding='post')\n",
    "decoder_input_test = pad_sequences(decoder_input_test, maxlen=headlines_max_len, padding='post')\n",
    "decoder_target_test = pad_sequences(decoder_target_test, maxlen=headlines_max_len, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4904114e",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### ✔️ Step 2. 모델 설계하기\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83fde51",
   "metadata": {},
   "source": [
    "**⭐ 1) 인코더 설계**\n",
    "<br>\n",
    "\n",
    "- 함수형 API를 이용해서 인코더를 설계한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "335ddbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "# 인코더 설계 시작\n",
    "embedding_dim = 128\n",
    "hidden_size = 256\n",
    "\n",
    "# 인코더 설계\n",
    "encoder_inputs = Input(shape=(text_max_len,))  # text_max_len = 50\n",
    "\n",
    "# 인코더의 임베딩 층\n",
    "enc_emb = Embedding(src_vocab, embedding_dim)(encoder_inputs) # src_vocab = 2000\n",
    "\n",
    "# 인코더의 LSTM 1\n",
    "# encoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4, recurrent_dropout = 0.4)\n",
    "encoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "# 인코더의 LSTM 2\n",
    "# encoder_lstm2 = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_lstm2 = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "# 인코더의 LSTM 3\n",
    "# encoder_lstm3 = LSTM(hidden_size, return_state=True, return_sequences=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_lstm3 = LSTM(hidden_size, return_state=True, return_sequences=True, dropout=0.4)\n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829b7a9e",
   "metadata": {},
   "source": [
    "- 임베딩 벡터의 차원은 128로 정의하고, hidden state의 크기는 256으로 정의했다. <br>(hidden state는 LSTM에서 얼만큼의 수용력(capacity)을 가질지 정하는 파라미터이다. 이 파라미터는 LSTM의 용량의 크기나, LSTM에서의 뉴런의 갯수라고 이해할 수 있다.)<br><br>\n",
    "- 인코더의 LSTM은 총 3개의 층으로 구성해서 모델의 복잡도를 높였다. <br>\n",
    "- hidden state의 크기를 늘리는 것이 LSTM 층 1개의 용량을 늘린다면, 3개의 층을 사용하는 것은 모델의 용량을 늘린다고 볼 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3f04d6",
   "metadata": {},
   "source": [
    "**⭐ 2) 디코더 설계**\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dd604eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 설계\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "# 디코더의 임베딩 층\n",
    "dec_emb_layer = Embedding(tar_vocab, embedding_dim)  # tar_vocab = 9000\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 디코더의 LSTM\n",
    "decoder_lstm = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=[state_h, state_c])\n",
    "# 디코더의 LSTM을 정의할 때, initial_state의 인자값으로 인코더의 hidden state와 cell state의 값을 넣어준다.\n",
    "\n",
    "# 디코더 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')  \n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6becfa32",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**⭐ 3) 모델 정의**\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "46818be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 40)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 40, 128)      2560000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 40, 256), (N 394240      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 40, 256), (N 525312      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 128)    1152000     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 40, 256), (N 525312      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 256),  394240      embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 9000)   2313000     lstm_3[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 7,864,104\n",
      "Trainable params: 7,864,104\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad8bbc9",
   "metadata": {},
   "source": [
    "- 디코더의 출력층에서는 `tar_vocab`의 수많은 선택지 중 하나의 단어를 선택하는 다중 클래스 분류 문제를 풀어야 하므로, Dense 인자로 `tar_vocab`을 주고, 활성화 함수로 소프트맥스를 사용한다.<br><br>\n",
    "- 여태껏 설계한 모델은 인코더의 hidden state와 cell state를 디코더의 초기 state로 사용하는 가장 기본적인 `seq2seq` 이다.<br><br>\n",
    "- `attention mechanism`을 적용하여 디코더 출력층의 설계를 바꾸고 성능을 높여보자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12daf804",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**⭐ 4) 어텐션 메커니즘**\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e31207e",
   "metadata": {},
   "source": [
    "- 어텐션 메커니즘을 수행하는 어텐션 함수를 설계하는 것은 또 다른 새로운 신경망을 설계해야 한다는 것이지만 여기서는 TensorFlow에 이미 구현된 어텐션 함수를 가져와서 디코더의 출력층에 어떤 방식으로 결합하는지 배워본다.<br><br>\n",
    "- `Bahdanau` 스타일의 어텐션 메커니즘을 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3b6fe60f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 40)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 40, 128)      2560000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 40, 256), (N 394240      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 40, 256), (N 525312      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 128)    1152000     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 40, 256), (N 525312      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 256),  394240      embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AdditiveAttent (None, None, 256)    256         lstm_3[0][0]                     \n",
      "                                                                 lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 512)    0           lstm_3[0][0]                     \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 9000)   4617000     concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 10,168,360\n",
      "Trainable params: 10,168,360\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import AdditiveAttention\n",
    "\n",
    "# 어텐션 층(어텐션 함수)\n",
    "attn_layer = AdditiveAttention(name='attention_layer')\n",
    "\n",
    "# 인코더와 디코더의 모든 time step의 hidden state를 어텐션 층에 전달하고 결과를 리턴\n",
    "attn_out = attn_layer([decoder_outputs, encoder_outputs])\n",
    "\n",
    "\n",
    "# 어텐션의 결과와 디코더의 hidden state들을 연결\n",
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_concat_input)\n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fce69f9",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### ✔️ Step 3. 모델 훈련하기\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7bc13e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "256/256 [==============================] - 44s 75ms/step - loss: 6.5184 - val_loss: 6.1310\n",
      "Epoch 2/50\n",
      "256/256 [==============================] - 18s 69ms/step - loss: 5.9892 - val_loss: 5.7416\n",
      "Epoch 3/50\n",
      "256/256 [==============================] - 18s 70ms/step - loss: 5.6358 - val_loss: 5.4808\n",
      "Epoch 4/50\n",
      "256/256 [==============================] - 18s 70ms/step - loss: 5.3594 - val_loss: 5.2685\n",
      "Epoch 5/50\n",
      "256/256 [==============================] - 18s 71ms/step - loss: 5.1039 - val_loss: 5.0807\n",
      "Epoch 6/50\n",
      "256/256 [==============================] - 19s 72ms/step - loss: 4.8830 - val_loss: 4.9486\n",
      "Epoch 7/50\n",
      "256/256 [==============================] - 19s 73ms/step - loss: 4.6931 - val_loss: 4.8451\n",
      "Epoch 8/50\n",
      "256/256 [==============================] - 19s 73ms/step - loss: 4.5270 - val_loss: 4.7660\n",
      "Epoch 9/50\n",
      "256/256 [==============================] - 19s 73ms/step - loss: 4.3784 - val_loss: 4.6992\n",
      "Epoch 10/50\n",
      "256/256 [==============================] - 19s 74ms/step - loss: 4.2464 - val_loss: 4.6441\n",
      "Epoch 11/50\n",
      "256/256 [==============================] - 19s 74ms/step - loss: 4.1265 - val_loss: 4.6176\n",
      "Epoch 12/50\n",
      "256/256 [==============================] - 19s 75ms/step - loss: 4.0155 - val_loss: 4.5856\n",
      "Epoch 13/50\n",
      "256/256 [==============================] - 19s 74ms/step - loss: 3.9100 - val_loss: 4.5636\n",
      "Epoch 14/50\n",
      "256/256 [==============================] - 19s 75ms/step - loss: 3.8133 - val_loss: 4.5409\n",
      "Epoch 15/50\n",
      "256/256 [==============================] - 19s 75ms/step - loss: 3.7225 - val_loss: 4.5306\n",
      "Epoch 16/50\n",
      "256/256 [==============================] - 19s 75ms/step - loss: 3.6369 - val_loss: 4.5217\n",
      "Epoch 17/50\n",
      "256/256 [==============================] - 19s 75ms/step - loss: 3.5583 - val_loss: 4.5073\n",
      "Epoch 18/50\n",
      "256/256 [==============================] - 19s 75ms/step - loss: 3.4800 - val_loss: 4.5013\n",
      "Epoch 19/50\n",
      "256/256 [==============================] - 19s 75ms/step - loss: 3.4028 - val_loss: 4.5039\n",
      "Epoch 20/50\n",
      "256/256 [==============================] - 19s 75ms/step - loss: 3.3369 - val_loss: 4.5041\n",
      "Epoch 00020: early stopping\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', patience=2, verbose=1)\n",
    "\n",
    "history = model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train,\n",
    "          validation_data=([encoder_input_test, decoder_input_test], decoder_target_test),\n",
    "          batch_size=256, callbacks=[es], epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65afede1",
   "metadata": {},
   "source": [
    "- 조기 종료를 뜻하는 `EarlyStopping`은 특정 조건이 충족되면 훈련을 멈추는 역할을 한다.<br><br>\n",
    "    - 위 코드에서는 `val_loss`(검증데이터의 손실)을 관찰하다가, 검증 데이터의 손실이 줄어들지 않고 증가하는 현상이 2회(patient=2) 관측되면 학습이 멈추도록 설정되었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cd3694ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881acd7d",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### ✔️ Step 4. 인퍼런스 모델 구현하기\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e873d891",
   "metadata": {},
   "source": [
    "- 테스트 단계에서는 정수 인덱스 행렬로 존재하던 텍스트 데이터를 실제 데이터로 복원해야 하므로, 필요한 3개의 사전을 미리 준비해둔다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "16af165e",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_index_to_word = src_tokenizer.index_word # 원문 단어 집합에서 정수 -> 단어를 얻음\n",
    "tar_word_to_index = tar_tokenizer.word_index # 헤드라인 단어 집합에서 단어 -> 정수를 얻음\n",
    "tar_index_to_word = tar_tokenizer.index_word # 헤드라인 단어 집합에서 정수 -> 단어를 얻음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239a1058",
   "metadata": {},
   "source": [
    "- `seq2seq` 모델은 훈련할 때와 인퍼런스(실제 동작)할 때의 방식이 다르다.<br><br>\n",
    "    - 훈련 단계에서는 디코더의 입력부에 정답이 되는 문장 전체를 한꺼번에 넣고 디코더의 출력과 한 번에 비교할 수 있으므로, 인코더와 디코더를 엮은 통짜 모델 하나만 준비하면 된다.<br><br>\n",
    "    - 인퍼런스 단계(정답 문장이 없는)에서는 만들어야 할 문장의 길이만큼 디코더가 반복 구조로 동작해야 하기 때문에 부득이하게 인퍼런스를 위한 모델 설계를 별도로 해주어야 한다.<br><br>        \n",
    "        - 이때는 인코더 모델과 디코더 모델을 분리해서 설계한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f3711fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 설계\n",
    "encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "# 이전 시점의 상태들을 저장하는 텐서\n",
    "decoder_state_input_h = Input(shape=(hidden_size,))\n",
    "decoder_state_input_c = Input(shape=(hidden_size,))\n",
    "\n",
    "# 디코더 임베딩 층\n",
    "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용. 이는 뒤의 함수 decode_sequence()에 구현\n",
    "# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태인 state_h와 state_c를 버리지 않음.\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae5438a",
   "metadata": {},
   "source": [
    "- 어텐션 메커니즘을 사용하는 출력층을 설계한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f1d42a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 어텐션 함수\n",
    "decoder_hidden_state_input = Input(shape=(text_max_len, hidden_size))\n",
    "attn_out_inf = attn_layer([decoder_outputs2, decoder_hidden_state_input])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_outputs2 = decoder_softmax_layer(decoder_inf_concat) \n",
    "\n",
    "# 최종 디코더 모델\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b407ae",
   "metadata": {},
   "source": [
    "- 인퍼런스 단계에서 단어 시퀀스를 완성하는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "889984ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "    \n",
    "    # <sos>에 해당하는 토큰 생성\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = tar_word_to_index['sostoken']\n",
    "    \n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:  # stop_condition이 True가 될 때까지 루프 반복\n",
    "        \n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = tar_index_to_word[sampled_token_index]\n",
    "        \n",
    "        if sampled_token != 'eostoken':\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "        \n",
    "        # <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
    "        if (sampled_token == 'eostoken'  or len(decoded_sentence.split()) >= (headlines_max_len-1)):\n",
    "            stop_condition = True\n",
    "            \n",
    "        # 길이가 1인 타겟 시퀀스를 업데이트\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0,0] = sampled_token_index\n",
    "        \n",
    "        # 상태를 업데이트\n",
    "        e_h, e_c = h, c\n",
    "        \n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b900356",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### ✔️ Step 5. 모델 테스트하기\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7c9588",
   "metadata": {},
   "source": [
    "- 테스트 단계에서는 정수 시퀀스를 텍스트 시퀀스로 변환하여 결과를 확인하는것이 편하다. 따라서, 주어진 정수 시퀀스를 텍스트 시퀀스로 변환하는 함수를 만든다.<br><br>\n",
    "    - text의 정수 시퀀스에서는 패딩을 위해 사용되는 숫자 0을 제외하고, headlines의 정수 시퀀스에서는 숫자 0, 시작 토큰의 인덱스, 종료 토큰의 인덱스를 출력에서 제외하도록 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ecf7868b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2text(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if i!=0:\n",
    "            temp = temp + src_index_to_word[i]+' '\n",
    "    return temp\n",
    "    \n",
    "# headlines의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2headlines(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if ((i!=0 and i!=tar_word_to_index['sostoken']) and i!=tar_word_to_index['eostoken']):\n",
    "            temp = temp + tar_index_to_word[i]+' '\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4d0014b2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text                  : group cryptocurrency traders plan sue japanese exchange coincheck thursday last month theft million cryptocurrency according reports lawsuit demand coincheck allow withdrawals cryptocurrencies wallets outside exchange exchange frozen withdrawals yen cryptocurrencies following heist \n",
      "\n",
      "실제 headlines        : crypto traders sue japan exchange million hack \n",
      "\n",
      "추상적 요약 headlines :  crypto exchange exchange cryptocurrency exchange mn\n",
      "\n",
      "===============================================================================================\n",
      "\n",
      "text                  : senior aap leader delhi minister gopal rai monday refuted possibility party entering pre poll alliance congress lok sabha elections added post poll alliance depend totally situation aim clear want modi government go rai said \n",
      "\n",
      "실제 headlines        : pre poll alliance congress aap minister \n",
      "\n",
      "추상적 요약 headlines :  aap contest polls delhi assembly elections\n",
      "\n",
      "===============================================================================================\n",
      "\n",
      "text                  : condoling demise former prime minister atal bihari vajpayee tata group chairman emeritus ratan tata described great leader great sense compassion tata sons chairman chandrasekaran said nation lost statesman independent india vajpayee ji led india great wisdom love country \n",
      "\n",
      "실제 headlines        : great leader great sense tata vajpayee \n",
      "\n",
      "추상적 요약 headlines :  vajpayee vajpayee\n",
      "\n",
      "===============================================================================================\n",
      "\n",
      "text                  : union minister smriti irani wednesday posted picture skeleton bench wrote waited wedding instagram actors deepika padukone ranveer singh got married konkani ceremony italy wednesday however share pictures wedding \n",
      "\n",
      "실제 headlines        : waited long deepika ranveer wedding pics smriti irani \n",
      "\n",
      "추상적 요약 headlines :  deepika padukone shares picture deepika wedding\n",
      "\n",
      "===============================================================================================\n",
      "\n",
      "text                  : malayalam actor dileep said ready lie detector test prove innocence abduction assault south indian actress facebook post dileep wrote one thing say public media trying role cases \n",
      "\n",
      "실제 headlines        : ready lie detector test actress abduction case dileep \n",
      "\n",
      "추상적 요약 headlines :  irrfan khan slams indian actor khanna\n",
      "\n",
      "===============================================================================================\n",
      "\n",
      "text                  : directors seven firms booked running get rich quick racket across country cheating people nearly crore gurugram police said accused allegedly duped people promising double returns investments short period time sanjay main accused arrested gurugram police bhopal \n",
      "\n",
      "실제 headlines        : firms directors booked get rich fraud cr \n",
      "\n",
      "추상적 요약 headlines :  fake fake bank firm busted lakh crore\n",
      "\n",
      "===============================================================================================\n",
      "\n",
      "text                  : lady gaga bradley cooper earned nominations golden globe awards performances film star born gaga nominated alongside nicole kidman best actress drama category cooper nominated best actor drama category along star among others \n",
      "\n",
      "실제 headlines        : lady gaga nominated golden globe awards \n",
      "\n",
      "추상적 요약 headlines :  wins best award awards\n",
      "\n",
      "===============================================================================================\n",
      "\n",
      "text                  : family members year old iit delhi graduate gupta committed suicide jumping institute building friday said idea went commit suicide relative said gupta quit job around months ago unhappy professional growth graduation gupta worked two years us \n",
      "\n",
      "실제 headlines        : idea went iit commit suicide gupta family \n",
      "\n",
      "추상적 요약 headlines :  delhi aspirant commits suicide commits suicide\n",
      "\n",
      "===============================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(2,10):\n",
    "    print('text                  :', seq2text(encoder_input_test[i]))\n",
    "    print('\\n실제 headlines        :', seq2headlines(decoder_input_test[i]))\n",
    "    print('\\n추상적 요약 headlines :', decode_sequence(encoder_input_test[i].reshape(1, text_max_len)))\n",
    "    print('\\n===============================================================================================\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337c1ab5",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "# Ⅱ. 추출적 요약\n",
    "\n",
    "---\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2ffe21",
   "metadata": {},
   "source": [
    "**⭐ 1) 중복 샘플과 NULL 값이 존재하는 샘플 제거<br>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "78aae8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(98401, 2)\n",
      "Index(['headlines', 'text'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/sunnysai12345/News_Summary/master/news_summary_more.csv\", filename=\"news_summary_more.csv\")\n",
    "data = pd.read_csv('news_summary_more.csv', encoding='iso-8859-1')\n",
    "print(data.shape)\n",
    "print(data.columns)\n",
    "\n",
    "data=data[['text', 'headlines']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e3ecbad1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "수집된 뉴스기사 샘플의 수 : 98401\n",
      "text 열에서 중복을 배제한 유일한 샘플의 수 : 98360\n"
     ]
    }
   ],
   "source": [
    "print('수집된 뉴스기사 샘플의 수 :', len(data))\n",
    "print('text 열에서 중복을 배제한 유일한 샘플의 수 :', data['text'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ce400bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 98360\n"
     ]
    }
   ],
   "source": [
    "# inplace=True 를 설정하면 DataFrame 타입 값을 return 하지 않고 data 내부를 직접적으로 바꾼다.\n",
    "\n",
    "data.drop_duplicates(subset=['text'], inplace=True)\n",
    "print('전체 샘플수 :', len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8f4f9076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text         0\n",
      "headlines    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4a149d",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### ✔️ Step 1. Summarize 사용하기\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6b744638",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from summa.summarizer import summarize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e581b67",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Summa의 summarize()의 인자로 사용되는 값들에 대해서 알아보자.**\n",
    "<br>\n",
    "\n",
    "> text(str) : 요약할 텍스트,<br>\n",
    "> ratio(float, optional) - 요약문에서 원본에서 선택되는 문장 비율. 0~1 사이값<br>\n",
    "> words(int or None, optional) - 출력에 포함할 단어 수.<br>\n",
    "> 만약, ratio와 함께 두 파라미터가 모두 제공되는 경우 ratio는 무시한다.<br>\n",
    "> split(bool, optional) - True면 문장 list , False는 조인(join)된 문자열을 반환<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd12defd",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### ✔️ Step 2. 모델 테스트하기\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ed7a151d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text                  : New Zealand defeated India by 8 wickets in the fourth ODI at Hamilton on Thursday to win their first match of the five-match ODI series. India lost an international match under Rohit Sharma's captaincy after 12 consecutive victories dating back to March 2018. The match witnessed India getting all out for 92, their seventh lowest total in ODI cricket history.\n",
      "\n",
      "실제 headlines        : New Zealand end Rohit Sharma-led India's 12-match winning streak\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_47/1408859814.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'text                  :'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n실제 headlines        :'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'headlines'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n추출적 요약 headlines :'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'. '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n===============================================================================================\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'text' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(2,10):\n",
    "    print('text                  :', data['text'][i])\n",
    "    print('\\n실제 headlines        :', data['headlines'][i])\n",
    "    print('\\n추출적 요약 headlines :', summarize(text[i], ratio=1/len(text[i].split('. '))))\n",
    "    print('\\n===============================================================================================\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b05ac3",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "# . Ⅲ 정리\n",
    "\n",
    "---\n",
    "\n",
    "<br><br>\n",
    "\n",
    "- 확실히 자연어 처리(Natural Language Processing)는 전처리 작업 서부터 모델학습 그리고 인퍼런스 모델까지 정말 다양한 과정을 수행해야만 테스트를 진행할 수 있었다. <br><br>\n",
    "\n",
    "--- \n",
    "- **1. 전처리를 하기위해...** <br><br>\n",
    "    - 첫번째로, 데이터를 정리하였는데 1) 중복된 문장이 있는지 살펴보았고 2) 빈 문장을 제거하였다. 3) 텍스트 정규화를 진행하였으며 4) NLTK(Natural Language Toolkit)를 사용하여 불용어 처리를 진행하였다.\n",
    "    - 두번째로, 훈련데이터와 테스트 데이터로 나누었다.\n",
    "    - 세번째로, 정수 인코딩을 진행하였다.<br><br>\n",
    "- **2, 모델 설계하기**<br>\n",
    "- **3, 모델 훈련하기**<br>\n",
    "- **4, 인퍼런스 모델 구현하기**<br>\n",
    "- **5, 모델 테스트하기**<br>\n",
    "- **6, 추출적 요약 해보기**<br><br>\n",
    "\n",
    "- 모델학습은 안정적으로 수렴됨을 그래프를 통해 확인하였다.\n",
    "![image](https://user-images.githubusercontent.com/103712369/169865722-1e837470-d302-4b49-85ed-4d945d1f46dc.png)<br>\n",
    "- Early Stopping 기능을 사용해서 val loss가 두번 이상 줄어들지 않으면 멈추는 기능을 사용하였다.<br>\n",
    "- 50번의 epoch중 23번까지 학습이 진행된 것을 확인할 수 있었다.<br><br>\n",
    "---\n",
    "\n",
    "- **Extractive / Abstractive 요약을 시도해보았다.** <br><br>\n",
    "![image](https://user-images.githubusercontent.com/103712369/169866233-7f0393eb-db72-46fd-9bf2-5e6da461ba9a.png)<br>\n",
    "    - 추상적 요약의 경우 정답 headlines와 높은 확률로 유사한 키워드를 포함하여 요약을 해내는 것을 위 그림을 통해 확인할 수 있다.<br><br>\n",
    "    \n",
    "![image](https://user-images.githubusercontent.com/103712369/169866708-74715b2e-b834-4560-b38b-add3150fb0fd.png)\n",
    "    - 추출적 요약의 경우 비교적 짧은 뉴스 문단에서 핵심 1개의 문장을 추출하도록 정의하였고, 실제로 하나의 중요한 문장이 출력되는 것을 확인할 수 있었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2049976f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6504cc24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106eb9c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1aee1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2340e5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27abcd2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ad40b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "49e4961e",
   "metadata": {},
   "source": [
    "======================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf08b16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
